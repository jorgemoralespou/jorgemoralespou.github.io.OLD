<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://jorgemoral.es/</id>
  <title>Learn the Origin</title>
  <updated>2017-04-19T11:00:00Z</updated>
  <link rel="alternate" href="http://jorgemoral.es/"/>
  <link rel="self" href="http://jorgemoral.es/atom.xml"/>
  <author>
    <name>Jorge Morales</name>
    <uri>http://jorgemoral.es/about/</uri>
  </author>
  <entry>
    <id>tag:jorgemoral.es,2017-04-19:/2017/04/chained-builds/</id>
    <title type="html">Enhancing your Builds on OpenShift. Chaining Builds.</title>
    <published>2017-04-19T11:00:00Z</published>
    <updated>2017-04-19T11:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2017/04/chained-builds/"/>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift provides different options for building and deploying containers on the platform.  These generally include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Build and deploy from application source code&lt;/strong&gt; - Users can specify the location of their source code in a GIT repository.  OpenShift will build the application binaries, then build the container images that include those binaries and deploy to OpenShift. Users can also specify a dockerfile as the source code to build container images from.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Build and deploy from application binaries&lt;/strong&gt; - Users can also specify the location of their application binaries, coming from their existing application build process and tools.  OpenShift will just build the container images that include those provided binaries and deploy to OpenShift.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Build outside of OpenShift&lt;/strong&gt; - Users can build their applications and container images completely outside of OpenShift, coming from their existing application and container image build process and tools, and specify the location of those images to pull in. OpenShift will just deploy those container image as provided.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_enhancing_your_builds_on_openshift_chaining_builds"&gt;Enhancing your Builds on OpenShift: Chaining Builds.&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As previously described, OpenShift provides a mechanism to bring your applications to run in containers on the platform, while abstracting much of the detail of the underlying container runtime, Kubernetes orchestration, and platform itself. This mechanism is called &lt;a href="https://docs.openshift.org/latest/architecture/core_concepts/builds_and_image_streams.html#source-build"&gt;s2i (source-to-image)&lt;/a&gt; which uses builder images to build your applications in containers. A builder image is a standard Docker/OCI image that contains additional builder scripts which can build your applications from source or binaries. In the case of Java, the builder images use Java build tools like Maven or Gradle to build an artifact type (jar, war, or ear) and will layer that on a java runtime (JDK, Tomcat, JBoss EAP, Wildfly-Swarm,&amp;#8230;&amp;#8203;) and the end result result will be packaged as a new container image for your application and deployed as a container.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In addition to the typical scenario of using source code as the input to a build, OpenShift build capabilities provides another build input type called “Image source”, that will stream content from one image (source) into another (destination).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Using this, we can combine source from one or multiple source images. And we can pass one or multiple files and/or folders from a source image to a destination image. Once the destination image has been built it will be pushed into the registry (or an &lt;a href="https://blog.openshift.com/pushing-application-images-to-an-external-registry/"&gt;external registry&lt;/a&gt;), and will be ready to be deployed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/image_source.png" alt="Image Source"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Using an image (or multiple) as the source of the content you want to stream into the destination image may appear unnecessarily complicated, but it opens the door to splitting the build process into two (or even more) different stages: &lt;strong&gt;build&lt;/strong&gt; and &lt;strong&gt;assemble&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;strong&gt;build&lt;/strong&gt; stage will use a regular source to image process and will pull down your application source code from Git and build it into an application artifact, publishing a new image that contains the built artifact. That’s the sole goal for this stage. For this reason, we can have specialized images that will know how to build an application artifact (or binary) using building tools, like maven, Gradle, go, …&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;strong&gt;assemble&lt;/strong&gt; stage will copy the binary artifact from the “source” image built in the previous stage and put it in a well known location that a runtime image will use to look for this artifact. Examples of such images could be Wildfly, JBoss EAP, Tomcat, Java OpenJDK, or even scratch (a special image without a base). In this stage we will just need to indicate where the are artifacts located in the source image and where they need to be copied in the destination image. The build process will create an image that will be pushed into the registry and will be known as the application image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/chaining.png" alt="Chaining builds"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now, I’m going to demonstrate this process with three different examples, that will give us the following benefits:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Build the app binaries with a regular s2i builder image and run the app using a vanilla (non s2i) image as the base image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Build the app binaries with a custom s2i builder image with a build tool (like Gradle), and run the app using an officially supported s2i image as the base.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make a minimal runtime image (which has many side benefits).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
At the end of each example there is the complete code snippet that you can use to reproduce the example in your own environment.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_example_1_maven_builder_non_s2i_wildfly_runtime"&gt;Example 1: Maven builder + non-s2i Wildfly Runtime&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this example I will use as runtime image a vanilla wildfly image, which will give me a smaller final image size compared to the s2i version of wildfly. I will use &lt;a href="https://hub.docker.com/r/jboss/wildfly/"&gt;the community version of wildfly available at Docker Hub&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/1-wildfly-size.png" alt="Wildfly image sizes"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I’ll use &lt;a href="https://github.com/minishift/minishift"&gt;minishift&lt;/a&gt; to start a local OpenShift cluster on my laptop to run these examples, but any OpenShift environment will work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I’ll start my minishift environment:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/minishift_start.png" alt="minishift start"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once I have my local environment up and running, I’ll create a new-project to isolate all the changes I do:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/1-newproject.png" alt="New project"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this example, I’m going to chain two builds. The first build will use any of the available java based s2i builders in OpenShift, as I only want to build my Java artifact using maven. I’ll use the &lt;a href="https://hub.docker.com/r/openshift/wildfly-101-centos7/"&gt;s2i-wildfly builder image&lt;/a&gt;, and will build a &lt;a href="https://github.com/OpenShiftDemos/os-sample-java-web"&gt;sample Java application which I have available in GitHub&lt;/a&gt;. Additionally I’ll give this build a name. Let’s keep it simple and call it “&lt;strong&gt;builder&lt;/strong&gt;”.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/1-newbuild-builder.png" alt="Builder image build"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once the build has finished, which you can verify by watching the build log, I’ll create a second build that will copy the generated artifact from the first build into the second. This second build will use jboss/wildfly image as base, and will copy the ROOT.war artifact from the builder image into the appropriate location. This second build will be a docker build and not a source build, like the previous. I’ll give this build a representative name again. This time the name will be “&lt;strong&gt;runtime&lt;/strong&gt;”.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/1-newbuild-runtime.png" alt="Runtime image build"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now I already have my runtime image built, with the application artifact. The only thing missing is to have the application deployed, so I’ll start a new-app from the “runtime” image, and will give it again a meaningful name, “&lt;strong&gt;my-application&lt;/strong&gt;”. Then, I’ll create a route and verify that the application is up and running.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/1-new-app.png" alt="New application"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is a simple example where I’m using a non-s2i image to run my application built in OpenShift. I could have used any Docker image, it doesn’t need to be jboss/wildfly, but I used this one since you already know where I work ;-)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You’ll see this application like any other application on the OpenShift Overview.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/1-overview.png" alt="Overview UI"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The main difference is that your application will have two builds, and the application itself, the code, will be built by the “builder” build, in case you want to set a GitHub webhook for your source code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/1-builds.png" alt="Builds"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you want to exercise all the code yourself, you only need to copy and paste the following snippet, which is also available in &lt;a href="https://github.com/jorgemoralespou/ose-chained-builds/blob/master/maven-jbosswildfly/example.sh"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc new-project maven-jbosswildfly
oc new-build wildfly~https://github.com/OpenShiftDemos/os-sample-java-web --name=builder

# watch the logs
oc logs -f bc/builder --follow

# Generated artifact is located in /wildfly/standalone/deployments/ROOT.war
oc new-build --name=runtime --docker-image=jboss/wildfly \
     --source-image=builder \
     --source-image-path=/wildfly/standalone/deployments/ROOT.war:. \
     --dockerfile=$'FROM jboss/wildfly\nCOPY ROOT.war /opt/jboss/wildfly/standalone/deployments/ROOT.war'


oc logs -f bc/runtime --follow

# Deploy and expose the app once built
oc new-app runtime --name=my-application
oc expose svc/my-application

# Print the endpoint URL
echo “Access the service at http://$(oc get route/my-application -o jsonpath='{.status.ingress[0].host}')/”&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let’s now explore a different use case for which chained builds can be helpful.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_example_2_gradle_builder_jdk_runtime"&gt;Example 2: Gradle builder + JDK Runtime&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;What happens when you want to to run your application with our officially supported OpenJDK image which has been created to run your Java based microservices, but your source code needs to be built using “Gradle”, which is not available in that image?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this example I will leverage a builder image I created with support for Gradle (&lt;a href="https://github.com/jorgemoralespou/s2i-java"&gt;jorgemoralespou/s2i-java&lt;/a&gt;) for a &lt;a href="https://blog.openshift.com/using-openshift-enterprise-grade-spring-boot-deployments/"&gt;previous post&lt;/a&gt;, and then, as in the previous example, I will copy the generated artifact into the official openjdk18-openshift image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For brevity I will only paste the snippet that does all, as the process was already explained in the previous example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The only caveat to this process is that you need to know where the built artifact is left in the builder image and where you need to place the artifact in the runtime image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc new-project gradle-jdk
oc new-build jorgemoralespou/s2i-java~https://github.com/jorgemoralespou/s2i-java \
   --context-dir=/test/test-app-gradle/ --name=builder

sleep 1

# watch the logs
oc logs -f bc/builder --follow

# Generated artifact is located in /wildfly/standalone/deployments/ROOT.war
oc new-build --name=runtime \
   --docker-image=registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift \
   --source-image=builder --source-image-path=/opt/openshift/app.jar:. \
   --dockerfile=$'FROM registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift\nCOPY app.jar /deployments/app.jar'

sleep 1

oc logs -f bc/runtime --follow

# Deploy and expose the app once built
oc new-app runtime --name=my-application
oc expose svc/my-application

# Print the endpoint URL
echo “Access the service at http://$(oc get route/my-application -o jsonpath='{.status.ingress[0].host}')/”&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We have created two different builds, one for building my application and another one for creating the runtime application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/2-builds.png" alt="Builds"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The deployed application can be seen in the overview page.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/2-overview.png" alt="Overview UI"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Clicking on the route you’ll see the cool example in action.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/2-app.png" alt="Application"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As can be seen, in the process, there are 4 ImageStreams involved:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/2-imagestreams.png" alt="ImageStreams"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The two base images used, s2i-java for building using Gradle, and openjdk18-openshift to be used as base for running our application. Also there is a builder and runtime ImageStream as result of our builds. Our deployment is based on the “runtime” ImageStream.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that we’ve seen how to use a different builder technology than the available in the images we want to run, let’s explore a final example on how to get a minimal runtime image.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_example_3_s2i_go_builder_scratch_runtime"&gt;Example 3: S2I Go builder + Scratch Runtime&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Go is a language where you run a “standalone” binary that can be statically compiled to have all the dependencies it requires. In this way, you can run a minimal image with a go binary that is easy to distribute.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As there is no official go-s2i image, I have modified the one available in &lt;a href="https://github.com/openshift-s2i/s2i-go"&gt;GitHub&lt;/a&gt; to statically build a binary. The source code for this image is available in &lt;a href="https://github.com/jorgemoralespou/s2i-go"&gt;GitHub&lt;/a&gt; and the image is published in Docker Hub under &lt;a href="https://hub.docker.com/r/jorgemoralespou/s2i-go/"&gt;jorgemoralespou/s2i-go&lt;/a&gt;. Keep in mind this image has been built just to prove this use case and that given my lack of expertise in go, you shouldn’t trust it (or use it) for anything important.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I have an example go application that is a web server showing a &lt;a href="https://github.com/jorgemoralespou/ose-chained-builds/blob/master/go-scratch/hello_world/main.go"&gt;hello-world in GitHub&lt;/a&gt;, and will be used for this third example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As before, and given that the process is the same, I’ll just paste the code snippet that you can copy and paste in your terminal to verify yourself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc new-project go-scratch
oc import-image jorgemoralespou/s2i-go --confirm
oc new-build s2i-go~https://github.com/jorgemoralespou/ose-chained-builds \
   --context-dir=/go-scratch/hello_world --name=builder

sleep 1

# watch the logs
oc logs -f bc/builder --follow

# Generated artifact is located in /opt/app-root/src/go/src/main/main
oc new-build --name=runtime \
   --docker-image=scratch \
   --source-image=builder \
   --source-image-path=/opt/app-root/src/go/src/main/main:. \
   --dockerfile=$'FROM scratch\nCOPY main /main\nEXPOSE 8080\nENTRYPOINT ["/main"]'

sleep 1

oc logs -f bc/runtime --follow

# Deploy and expose the app once built
oc new-app runtime --name=my-application
oc expose svc/my-application

# Print the endpoint URL
echo “Access the service at http://$(oc get route/my-application -o jsonpath='{.status.ingress[0].host}')/”&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once the process has finished, we can compare the size of the images. The builder image would be my application image if I wouldn’t have chained into a new build. The runtime image, as it is based off SCRATCH and has just the statically built binary, is 150x smaller in size.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/3-imagesize.png" alt="Image sizes"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_make_it_simple_make_it_repeatable"&gt;Make it simple, make it repeatable&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that we have set up 3 different use cases to which chaining builds can provide some benefit, we can abstract all these complexity in a template, so we just need to instantiate a template providing the location of our source code repository and the name of our application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/chained_builds/3-template.png" alt="Template"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Additionally we can augment this template with any parameterization we might want to make configurable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;It is also important to note that using some of the building capabilities provided by OpenShift we have set up an ImageChangeTrigger on the second build so there is no need to manually launch both builds. The second build will be started by OpenShift once the first has finished as a result of the new image being created by the first build.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Using a template simplifies your user experience and provides you a mechanism to create this type of applications with a single command:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc new-app go-scratch \
           -p name=my-application \
           -p GIT_URI= https://github.com/jorgemoralespou/ose-chained-builds \
           -p CONTEXT_DIR=/go-scratch/hello_world&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_conclusions"&gt;Conclusions&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To conclude this article, I want you to think about all the capabilities that the platform provides and that sometimes are not obvious to us. With this technique, we can do much more fancy things, that I will show in a follow up blog.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, as many of you would have probably figured out, there’s not only benefits in what I just showed. There will be two docker images being built, pushed and stored in the registry and there will be a bigger maintenance burden. But, the most important thing to understand is that the platform does not limit us in many ways that we could have thought of.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As always, the complete content used for this blog is available in &lt;a href="https://github.com/jorgemoralespou/ose-chained-builds"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I hope that this has given you some food for thought. Happy to chat about it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">Chaining builds in OpenShift you can do fancy things like using an alternate builder tool, using an alternate runtime, or making a slim runtime image.</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2017-04-08:/2017/04/developing-locally-openshift-minishift/</id>
    <title type="html">Developing locally with OpenShift - minishift, bringing it all together</title>
    <published>2017-04-08T11:00:00Z</published>
    <updated>2017-04-08T11:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2017/04/developing-locally-openshift-minishift/"/>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;We finally get to the last post of the series, and in this post I will introduce you to the tool that Developers will be using soon. It’s still not final and yet many features need to be planned and included, but will overcome all the problems I described in my previous posts.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There’s already a good blog post from &lt;a href="https://github.com/LalatenduMohanty"&gt;Lalatendu Mohanty&lt;/a&gt; about &lt;a href="https://developers.redhat.com/blog/2017/02/28/using-red-hat-container-development-kit-3-beta/"&gt;what CDKv3 is&lt;/a&gt; so I will not go into many details. I will just simply quote him for what I consider the most important part:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;“Minishift is a fork of the Minikube project and uses libmachine to interact with the underlying virtualization software. It also uses OpenShift’s “cluster up” functionality for provisioning the local Origin/OCP cluster”&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;“At the moment, KVM, Virtualbox, Xhyve and HyperV are the supported hypervisors.”&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You should note that from this 2 sentences there is so many relevant things to mention:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;First, and foremost, the tool runs in a virtual machine, providing isolation from the host. Also, the support for the most common virtualization technologies across all major Operating Systems, providing consistency on where minishift can be run. And finally, minishift uses internally “oc cluster up” which is the preferred way to bootstrap a local cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One of the key aspects of minishift is that it is a tool created with developers in mind, so most of the shortcomings that “oc cluster” provides are meant to be overtaken by minishift. But, not only is a tool for developers, it’s also a tool to have reproducible OpenShift local environments. This aspect is key for some alternative use cases, like teaching or showing OpenShift capabilities in a reproducible manner. Evangelism of OpenShift will greatly benefit from the sweetness that minishift provides.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As an example of things that are or will be shortly possible:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reuse downloaded images from VM to VM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provision a set of addons/bundles upon cluster creation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Modify cluster default behavior&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provide multiple openshift instances/profiles&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ability to pack and transfer files required to have a working environment&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_how_to_get_started"&gt;How to get started&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To work with minishift is as easy as it is to work with “oc cluster”. It’s a single go binary compiled for the different major developers operating systems (Windows, Mac and Linux). The only pre-requirement is that you have any of the supported virtualization technologies available on your workstation. Once you have the binary downloaded, and for convenience, added to the path, you can just issue one command:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre&gt;$ minishift start&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This command, which accepts a variety of configuration flags, does all you need to have OpenShift up and running. It will pull down a boot-2-docker iso (there’s also Centos and RHEL variants), it will create a VM using that iso image, and will do “oc cluster up” within the VM, with the appropriate configuration. After all the images have been pulled down (which can take a while) you’ll have a complete OpenShift all in one cluster running in a VM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once you finish working, you just need to stop the VM, by doing:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre&gt;$ minishift stop&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Note that this will keep the VM in your workstation, so you can start and stop it several times being sure that your work will be preserved.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once you’re done, you can discard the VM and recover all used disc space, by doing:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre&gt;$ minishift delete&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_conclusions"&gt;Conclusions&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Although minishift has not even hit version 1.0.0 GA it is already one of the easiest ways to work with Openshift locally. But the truth is that if the present is encouraging the future is promising, and we will see a great deal of capabilities being added moving forward that will keep simplifying developers life, so that a regular developer will not need to know how to install, manage, configure and operate and OpenShift cluster and will be able to keep focus in what should be important to him, develop applications that will ultimately run on an OpenShift cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I have to say that these past months where I’ve been working with the minishift team, they have proved that “being the tool of choice for developers” is their main goal, and they have been listening to all the feedback from the community to make the experience as easy as possible. I want to thank &lt;a href="https://github.com/hferentschik"&gt;Hardy Ferentschik&lt;/a&gt;, &lt;a href="https://github.com/LalatenduMohanty"&gt;Lalatendu Mohanty&lt;/a&gt;, &lt;a href="https://github.com/praveenkumar"&gt;Praveen Kumar&lt;/a&gt;, &lt;a href="https://github.com/budhrg"&gt;Budh Ram Gurung&lt;/a&gt;, &lt;a href="https://github.com/gbraad"&gt;Gerard Braad&lt;/a&gt;, and the rest of the &lt;a href="https://github.com/minishift/minishift/graphs/contributors"&gt;minishift team&lt;/a&gt;, and also specially &lt;a href="https://github.com/jimmidyson"&gt;Jimmy Dyson&lt;/a&gt; who started this project.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">In this last post I'm introducing what is the definitive tool for working with OpenShift locally and where we'll be investing moving forward.</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2017-04-07:/2017/04/developing-locally-openshift-oc-cluster/</id>
    <title type="html">Developing locally with OpenShift - “oc cluster up”, the fastest way to get a local cluster</title>
    <published>2017-04-07T11:00:00Z</published>
    <updated>2017-04-07T11:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2017/04/developing-locally-openshift-oc-cluster/"/>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Some time after we launched, we realized how easy it was to run OpenShift itself as a Docker container, as that’s one of the possible ways to install and run OpenShift. Our lead architect, &lt;a href="https://github.com/smarterclayton/"&gt;Clayton Coleman&lt;/a&gt;, realized that since every developer will probably have the “oc” (OpenShift client) client tool available on their machines, it could be very easy to add some behaviour to that client to bootstrap a local OpenShift instance. This is how he came with the command cluster and the options up and down.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;“oc cluster up”&lt;/strong&gt; will start an openshift all-in-one Docker container on your workstation and it will do some bootstrapping to make it usable. With the command comes many switches so that the behaviour can be customized.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;“oc cluster down”&lt;/strong&gt; will stop that container and remove any configuration used by it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A subsequent start of a cluster, again with “oc cluster up” will bring up a fresh new cluster. This means that the cluster that you have started is not persisted by default, unless one uses the switch “--keep-config” that will preserve the configuration upon restarts.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;How does “oc cluster” works? It runs an origin (or ocp) Docker container natively and then it does some bootstrapping to provide some initial configuration. Wait? Did I say a Docker container natively? Yes. This means that for Windows and Mac users you’ll need to use either Docker for Windows or Docker for Mac respectively. Docker for Windows and Docker for Mac uses lightweight virtualization (hyper-V and xhyve respectively) and start a Boot-2-Docker VM, that is very small in size (around 35 MB).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_how_to_get_started"&gt;How to get started&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Download the oc client from &lt;a href="https://github.com/openshift/origin/releases"&gt;origin releases&lt;/a&gt; (lookup for the latest stable)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/developing_locally_openshift/origin_releases.png" alt="Origin releases"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Next, start the cluster:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc cluster up&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/developing_locally_openshift/insecure_registry_error.png" alt="Insecure registry error"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You’ll get a warning about the registry. Just add the registry to the list of insecure registries of your Docker installation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/developing_locally_openshift/add_registry.png" alt="Add registry"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;At this point you have a fully functional openshift cluster up and running and available to you. The OpenShift console address is displayed in the output messages, but can also be queried by issuing the following command: at “oc whoami --show-server”. On the startup log there will also be user related information.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/developing_locally_openshift/cluster_started.png" alt="Add registry"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When you’re done working, just do:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc cluster down&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There’s a lot of command line switches to customize the cluster behavior. Starting a cluster for a different origin version or configuring proxies for your cluster are some of the things that can be easily configured.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_evolution"&gt;Evolution&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;“oc cluster” started as a way for OpenShift engineers to have a cluster up to test their work and soon became the easier way to start a cluster. It was first introduced in 1.3 and it has been adding some features on every release, although just the minimal required features for the intended goal. OpenShift version 1.4/3.4 introduced the ability to bootstrap a proxy and some other behavioral changes. OpenShift 1.5/3.5 will introduce Persistent Volumes, so anytime a cluster is bootstrapped, 100 PV will be created and available for the developer to use.
There is a lot of &lt;a href="https://github.com/openshift/origin/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue%20is%3Aopen%20in%3Atitle%20%22oc%20cluster%22%20"&gt;work going&lt;/a&gt; into the tool.
Although many engineers have contributed to this tool, most of the work has been done by &lt;a href="https://github.com/csrwng/"&gt;Cesar Wong&lt;/a&gt;. So my most sincere kudos to Cesar for his amazing work.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_is_it_enough"&gt;Is it enough?&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let’s start by saying that I love “oc cluster” as it gives an easy way to bootstrap a cluster based of a Docker container. This is the fastest way to get a cluster up and running. It only requires you to have the oc client, which if you use OpenShift at all you will already have it. And it’s easy to learn. You just need to remember 2 commands “oc cluster up” and “oc cluster down”.
On the contrary, I have to say that the default behavior does not make developing applications for that local OpenShift environment agile, as you’ll most likely not use the default behavior and will need to always provide command line switches.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The goal of this tool is not to provide a local, reusable, development environment, for those that develop applications that will run on OpenShift. It just provides a fast way to have a cluster available. In many cases, this will be sufficient, but not for me, and what I’m looking for as developer of applications for OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The workflow I look for as a developer of applications for Openshift should look like:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Start an env&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Work on it&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop an env&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start another env&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bootstrap it differently for that project&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop that env&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start, develop, stop&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Destroy a no longer needed env.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This has been the main motivation for me to start a side project, a bash script that wraps “oc cluster” and gives me the workflow I’m looking for. The script is named “oc-cluster” and is &lt;a href="https://github.com/openshift-evangelists/oc-cluster-wrapper"&gt;available on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="__oc_cluster_wrapper_gaining_experience_with_developers"&gt;“oc-cluster” wrapper: Gaining experience with developers.&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In the process of creating this tool I have done many experimentation on what would be the common bootstrapping that I would require so I have provided a mechanism to configure anything else that I don’t consider basic in an easy way than what is provided out of the box. There is a plugin mechanism that allows all these add ons to be installed on demand and they can be easily shared between different people.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The mechanics are the same as the base “oc cluster”, but it provides a default additional parameter which is the name of the cluster to start. This allows the developer to have multiple clusters created and start/stop the one with the work/add ons they want.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster up [PROFILE]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/developing_locally_openshift/oc-cluster_up.png" alt="oc-cluster up"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster stop&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/developing_locally_openshift/oc-cluster_down.png" alt="oc-cluster down"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is all you need to know, but as I have introduced the concept of profiles, you can then list the available clusters to decide which one you want to start in case you don’t remember the name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/developing_locally_openshift/oc-cluster_list.png" alt="oc-cluster list"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, as the clusters are now long lived, you will be able to completely delete the cluster if you’re not going to work with it any more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/developing_locally_openshift/oc-cluster_destroy.png" alt="oc-cluster destroy"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The tool has a lot of features targeting make developing on openshift easy, so if you want more information in how this tool works and all the capabilities it has, I recommend you to read the &lt;a href="https://github.com/openshift-evangelists/oc-cluster-wrapper/blob/master/README.adoc"&gt;README.adoc in GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_conclusions"&gt;Conclusions&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;“oc cluster” it’s an awesome tool to get a cluster up and running, but it really don’t fulfill all my expectations for using it as my local development environment for a day to day development tool. That is the reason has has driven me to create a tool on top.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The biggest advantage of this tool that created on top is that it totally adjusts to my workflow and expectations, as it is developed by me ;-), and it’s developed in my free time. Windows is not supported as bash does not run there natively.
There’s an alternative to this script, written by &lt;a href="https://github.com/GrahamDumpleton"&gt;Graham Dumpleton&lt;/a&gt;, written in Python, which supports Windows as well as MacOS X and Linux, called &lt;a href="https://github.com/getwarped/powershift-cluster"&gt;Powershift&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This side project has been mainly developed to make my daily life easier, but by sharing it, I’ve been collecting a big understanding on what users would expect when working with OpenShift locally, either for development or for any other purpose, like demos or even evangelism.
All this feedback is being constantly shared with the people working on “oc cluster” and “minishift”, to make continuously improve these tools, as these are officially provided by Red Hat.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;What’s &lt;strong&gt;minishift&lt;/strong&gt;? &lt;strong&gt;minishift&lt;/strong&gt; is the definitive tool for local OpenShift for development. If you want to know more, don’t forget to read the final blog in this series.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">In this 3rd blog in the series, we're exploring what is the fastest way to stand up an OpenShift cluster for development, and I'll introduce you to a tool that I've created for experimentation on additional use cases</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2017-04-06:/2017/04/developing-locally-openshift-origin-all-in-one/</id>
    <title type="html">Developing locally with OpenShift - Origin all in one. Where we started</title>
    <published>2017-04-06T11:00:00Z</published>
    <updated>2017-04-06T11:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2017/04/developing-locally-openshift-origin-all-in-one/"/>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;At the time OpenShift started, we realized that having a local development environment was important to make iterative development work more agile. Back then, the requirements that we had for a local development environment were pretty clear:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It needs to work on linux, mac and windows&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It needs to be easy to run&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It needs to be easily disposable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Resources used need to be adjustable&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There was an existing technology that was meeting all these requirements, Vagrant by Hashicorp. Vagrant is a tool that allows you to start a VM, from a template, and then provision/bootstrap the VM on first boot. Then you could start and stop that VM for as many times as you want/need before you discard it. This technology provided us a way to give a base VM image, based out of Centos or RHEL, that was on first boot bootstrapped to contain a full OpenShift environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The OpenShift evangelist team started this work and created what we called the “&lt;strong&gt;Origin all-in-one&lt;/strong&gt;” which bootstrapped you an OpenShift Origin all-in-one node with additional content. This effort also started based on the necessity of the team to provide a way for developers to have a VM they could take home in order to learn OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The effort lead to an official variant, called &lt;strong&gt;CDK (Container Development Kit)&lt;/strong&gt; and supported by our Red Hat Developers Tools, that was based on Red Hat Enterprise Linux and installed the Enterprise version of OpenShift, now called OpenShift Container Platform. It provides mostly the same capabilities as the all-in-one, but the most important fact for this variant is that Red Hat supports it. You just need to subscribe the VM (free subscription for developers) and you’ll have access to our Enterprise product.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The downsides to using Vagrant is that you need to use a full Operating System VM that required an initial download of some GBs of data prior to being able to start working. Also it requires a considerable amount of resources not always easily available in the developer’s workstations or laptops.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Relying on Vagrant seemed the right approach at the time, and in the case of CDK, Red Hat invested in having a team of developers working upstream on some of the plugins used. The truth is that after some time, Vagrant seems more an abandoned project where every release breaks a feature and introduces incompatibilities with some of the versions of the hypervisors, e.g. VirtualBox which makes it complicated for the users to have it properly installed and functional.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I’m not going to explain how this approach works. If you’re interested you can just look at &lt;a href="https://github.com/openshift-evangelists/vagrant-origin/"&gt;our docs&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Even though we could admit that the Origin all-in-one VM has been very successful, it has become less and less the defacto way of running a local OpenShift instance, and it will no longer be maintained, as we have &lt;a href="https://blog.openshift.com/goodbye-openshift-all-in-one-vm-hello-minishift/"&gt;announced&lt;/a&gt;. But don’t be afraid, that doesn’t mean there will be no solution. In the following posts I’ll be talking about more options, so stay tuned!&lt;/p&gt;
&lt;/div&gt;</content>
    <summary type="html">In part 2 of this series of articles we will explore the first local development environment that existed for Openshift Origin and OpenShift 3.</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2017-04-05:/2017/04/developing-locally-openshift-state-of-the-art/</id>
    <title type="html">Developing locally with OpenShift - State of the art</title>
    <published>2017-04-05T21:00:00Z</published>
    <updated>2017-04-05T21:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2017/04/developing-locally-openshift-state-of-the-art/"/>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift v3 launched a year and a half ago and during this time we’ve been looking at different ways to run a local OpenShift development environment on the developer’s laptop. In this series of articles I will be introducing the options we have been providing and most importantly, I will describe the evolution in our approach..&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;But before digging into any particular solution, we need to set the ground rules of what a local development environment is and why it is important.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift is a Cloud Container Application Platform that will usually be installed on a datacenter for enterprise grade usage. This means that developers will have access to a set of nodes that will be acting as development environment for them. As you probably know, OpenShift runs applications packaged as Docker containers, so all that is required to use the platform is the Docker images to run. How you get to these images is not relevant for OpenShift, although it provides some mechanism out of the box that makes your life easier, what is really relevant is that your Docker image is available to the platform.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As a developer, how can you make this happen? These are some options.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Provide source code to the platform and let the platform build it. There are 2 options:&lt;/p&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Provide your application’s source code and let OpenShift build the Docker image using s2i.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provide a Dockerfile and let OpenShift build the Docker image using a Docker build for you.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provide just your application binary to a special image that knows how to run it. This can be done in different ways but most likely:&lt;/p&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Provide your application binary to OpenShift and let OpenShift build a Docker image with the binary on top of an existing base image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provide your application binary as a parameter to your deployment that will use a generic Docker image and will pull it down at startup time. This goes against the model that the Docker image should container everything it needs, but still, is an option.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Docker image and push it to the platform. There is multiple ways to create this Docker image, build it locally or in a CI server running internally or externally to openshift.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pull down into the platform an existing Docker image. The only difference is that in this case, you will not be building the image.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;But let’s step back a little. Since we are developers, it is quite important to us how we create those Docker images. The truth is that, as developers, we will be building our application and trying it out on the environment several times during the development cycle. While doing this using a clustered platform, remote to our laptops, is probably the easiest in terms of convenience, but the truth is that for most developers, like me, this will not be enough. I will probably be building the application several times a day, sometimes tens or even hundreds of times. I will probably like to debug the running application. I will probably want to do many other things that can be summarized in:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;“I want to develop applications for OpenShift as fast as I can develop an application running on my local development box”&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;That probably means that&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I need to be able to have the OpenShift environment as close and available to me as possible&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I want to have a streamlined process for developing against this local OpenShift environment.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;While you may not agree with what I just said, I can provide some good reasoning on why I would like this kind of development environment. Of course there’s always some drawbacks, but I think they can be overcome. Let’s start with the pros on why it is good to have an OpenShift local.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Independence of location&lt;/strong&gt;. I no longer need to be attached to the company’s network to be able to work.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Independence of connectivity&lt;/strong&gt;. I will no longer require an internet connection to work. This is not always true, but is true as long as you have your dependencies and base images locally available. And this will work especially well if you integrate your image repository or source code repository into the local OpenShift. For example, this can be accomplished with Gitlab.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Customization of the experience&lt;/strong&gt;. I can customize the build experience so that it looks as close as possible to developing without OpenShift.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Faster development cycle&lt;/strong&gt;. I can iterate faster on my development, code, test, deploy, code, test, deploy, debug,&amp;#8230;&amp;#8203;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And now, the few cons I can think of:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Solutions for multiple platforms&lt;/strong&gt;. Developers might use Windows, Linux or Mac, so the local development environment needs to run on these Operating Systems.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Developer box resource requirements&lt;/strong&gt;. Having a local OpenShift install means that the Developer Workstation needs to have enough resources to run it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Administration rights to install the tools&lt;/strong&gt;. Sometimes we have found that developer’s workstations are standardized and they are not allowed to install additional software.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Of these cons, the first one is Red Hat’s responsibility, as we should provide a solution for local development targeting these different environments. The others are something that Enterprises will need to think about when adopting new technology. As we are already in 2017 we need to understand that developers will not be productive using low resources workstations, it’s penny-wise pound foolish. I hope that at this point in time, enterprises understand that specs for developer workstations should no longer be such a big issue.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There’s always alternatives to running a local OpenShift instance on the developer’s box, but I can not advocate for any solution that goes against the principles of test your production code as soon as possible, which for me, that means on my workstation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Most importantly,  there is multiple ways to bring your code into an application and that application to run it in your local OpenShift developer instance:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Building your application and rsync the compiled code into a running container.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rsync source code directly into a container when using non-compiled languages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using a maven plugin to build the images on the host and push them into you local OpenShift environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Many others&amp;#8230;&amp;#8203;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Any option you take, should mean that at the end you, as a developer, can test your application running in an OpenShift environment. If on the contrary, you build and verify/test your application in a specific way that will be different as how the application will be run in production, there’s many chances that issues might occur. This should be avoided as much as possible if you want to fully embrace DevOps and agility.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that I have presented the importance of having a local OpenShift environment available in your workstation, I’ll present the evolution of the “local OpenShift development environment” since we started to the present time, when I can say we have finally a really good solution that only can get better.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In the next blogs I’ll talk about the Origin all-on-one VM (and the Container Development Kit/CDK) using virtualization and Vagrant. Then I’ll move into a pure docker solution with “oc cluster up” and I’ll end up with minishift, a lightweight virtualized option.&lt;/p&gt;
&lt;/div&gt;</content>
    <summary type="html">This is the first article of a series of blogs describing the state of the art related to local development using OpenShift as Container Application Platform</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2016-10-20:/2016/10/developing-locally-with-openshift/</id>
    <title type="html">Developing locally with OpenShift</title>
    <published>2016-10-20T19:39:50Z</published>
    <updated>2016-10-20T19:39:50Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2016/10/developing-locally-with-openshift/"/>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog, I&amp;#8217;m going to describe what are my requirements when looking for a way to develop locally using OpenShift, and I&amp;#8217;ll describe a tool I have created to help me with this workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;First of all, I have to say that I&amp;#8217;m not only a developer, so maybe the workflow I&amp;#8217;m looking for is too complex, so I&amp;#8217;m still experimenting to refine not only the workflow but also the tooling. I&amp;#8217;ll give some comments on what I would like from my ideal tool.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, I need to say that this workflow is to work on OpenShift, as a developer, as an evangelist, as a product manager, as a tester, as a customer, as a user and the many roles I have throughout my day.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I&amp;#8217;ll use oc-cluster as the name of the command to show my needs. Why I used this name? Read to the end and I&amp;#8217;ll give you an answer and also a reason why the name will eventually change.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;First, I want an easy way to start and stop an OpenShift install locally, on my laptop.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster up
oc-cluster down&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I&amp;#8217;m somehow biased by some of the option names used by Vagrant, as I&amp;#8217;ve been a Vagrant user for many years, and still am, and I think some of the command names fits really well to be self descriptive.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One important thing for me is that the cluster I create will survive multiple days, as I will be using it for a while, so I need it to be persistent. That means that if I need a new cluster, I&amp;#8217;ll have to delete the current one, with:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster destroy&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Another important factor for me as I&amp;#8217;m multitasked, is to be able to have different clusters, with different stuff, that I can switch between them at will, so I have used the term &lt;strong&gt;profile&lt;/strong&gt; for this, and when starting, stoping and destroying a cluster I can use the profile name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster up java
oc-cluster down
oc-cluster up demo
oc-cluster down
oc-cluster destroy demo&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;While I can have everything in one single cluster, in different projects, if I end up adding a lot of applications to a cluster, the amount of resources I would use, and the time it would take to start would be high, so I&amp;#8217;d rather split my clusters into different responsibilities. I can create a cluster for Java development, configure it with a nexus artifact repository manager, and have templates configured to always use nexus, or have a buildOverrides for that. If I started a demo cluster, I would not be interfered by the work I do as a Java developer.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Next, as there can be multiple profiles, I need a way to know what profiles I have created, so I can pass the appropriate name to the &lt;strong&gt;up&lt;/strong&gt; command:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster list&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, it&amp;#8217;s very important to know if I already have a cluster up and running and which cluster is it:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster status&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;So far, this is a basic workflow to start and stop, create and destroy, list and status the clusters I have.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One important note is that since the create and start command is the same, the command needs to make sure that the first time is invoked will create the cluster, but the subsequent calls will just bring it up, and not do any creational steps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now, some of the needs that as a developer on OpenShift I have are to work with persistence volumes, so there are helper commands that helps on that goal.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster create-volume volumeName [size|10Gi] [path|$HOME/.oc/profiles/{profile}/volumes/{volumeName}]
oc-cluster create-shared-volume project/volumeName [size|10Gi] [path|$HOME/.oc/volumes/{volumeName}]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The first command will create an OpenShift PV, that is only available to the profile in use, that means that whenever I destroy the cluster represented by that profile, all the date stored in that volume will be removed as well. Like every developer, I expect that all the defaults are good enough for me to use, so I limit the amount of required params to just the name. This could also be reduced to use random names, and it&amp;#8217;s something I&amp;#8217;ll think about.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The second command, bring the difference that provides a shared storage between clusters. This way I can mount the same volume on multiple clusters. The main use case I have so far is to be used by persistent applications that I use in many clusters and that are used as infrastructure type of services. A good example for this is nexus artifact repository manager, where I want every dependency that I have already pulled down to be available to every cluster I use.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, talking about OpenShift, I will probably want to get into the OpenShift runner. What I mean with the OpenShift runner is the place where OpenShift is actually running, whether this is a VM or a docker container, and I want to do this in a consistent way and in a way that I will understand. For this I use:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster ssh&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now, I&amp;#8217;ll talk about some of the problems that my clusters could suffer and some solutions to those:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Adding functionality to the tool.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bootstrapping users&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bootstrapping the cluster&lt;/p&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Configuration bootstrap&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deployments bootstrap&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reproducibility&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Packaging/Transport&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using proxies&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I&amp;#8217;ll try to dive into all these topics, one by one.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_adding_functionality_to_the_tool"&gt;Adding functionality to the tool&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Sometimes I find that what I can do, or what I want to do, is not covered by the tool, and I understand that also my use case can be quite different from other&amp;#8217;s use cases. To solve this, the tool needs to support the ability to provide plugins that will help on different tasks. These tasks can be:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Bootstrapping tasks. Adding stuff to the cluster. Whether it&amp;#8217;s configuration or deployments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New commands. Having commands that extend how the tool works, and that are not considered bootstrapping but more management.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_bootstrapping_users"&gt;Bootstrapping users&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Users is a key part of local development environments, but it&amp;#8217;s more important when you want to use the local development environment for demos, as you&amp;#8217;ll probably want to have different users, with different roles and belonging to different projects, so you can show things like application promotions, or the difference way of working of a developer compared to an administrator.
For me, one of the most important parts, now that it is possible, is to have my regular user act as a &lt;strong&gt;sudoer&lt;/strong&gt;, so I can just execute admin commands if I need to without needing to change user.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This can be done by adding your user the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc adm policy add-cluster-role-to-user sudoer developer&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
My user is developer.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, I will probably need to log in as administrator to the web interface, so I need a full user with cluster-admin role.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc adm policy add-cluster-role-to-user cluster-admin admin&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
This action needs to be done as a system:admin, but the tooling we&amp;#8217;ve built take care of this.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Additionally I want to be able to create/delete users, and force them roles, so I can bootstrap a demo cluster for things like application promotions. I need some simple commands that will be able to bootstrap whatever is needed for me, no matter what underlying identity provider is used.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster create-user {username} {role} [{project}]
oc-cluster remove-user {username}
oc-cluster login {username}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You&amp;#8217;ll probably be wondering why there&amp;#8217;s a login and logout commands. This are needed as usually one can have multiple clusters created, with the same configuration, but sadly every cluster you create will have it&amp;#8217;s own self signed certificates for authenticating. There&amp;#8217;s a need to set in the local oc context the proper cluster and certificates, to avoid errors. This is handled by the &lt;strong&gt;login&lt;/strong&gt; command. As this is a &lt;strong&gt;local&lt;/strong&gt; environment, security is not much of a concern, and passwords can be generalized.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_bootstrapping_the_cluster"&gt;Bootstrapping the cluster&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Following with the things that need to be done are the need to provide some bootstrapping for the clusters, as there will be things I will need always to be provisioned/available in certain clusters.
For this, I think that it&amp;#8217;s important to have 2 possibilities, when creating clusters. First of all, is to blueprinting a cluster, so that every time you create a cluster with a certain blueprint, all the bootstrapping will be provided. And additionally, there needs to be a way to bootstrap one-shot clusters, for things you don&amp;#8217;t want so frequently.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To these, you have blueprints, that will be executed on cluster first bootstrap:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster up {profile_name} {blueprint}
oc-cluster up demo pipelines-demo&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Or you can do the provisioning afterwards, as a one-shot, as this will be executed in the same way:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster provision {blueprint}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;How do you know what blueprints you have?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster blueprints-list&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;All blueprints can be made composable, so there can be a repository with single actions (enable-pipelines, add-user, add-project, deploy-app) or a composed action (pipelines-demo,msa-demo,&amp;#8230;&amp;#8203;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_configuration_bootstrap"&gt;Configuration bootstrap&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Configuration bootstrapping is the one that requires changes in master or node config&amp;#8217;s file or any other configuration file and that probably will require a restart of the OpenShift process.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_deployments_bootstrap"&gt;Deployments bootstrap&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Deployments bootstrap does not require to restart any process as it will only interact with OpenShift deployable resources, like projects, users, services, routes, deployments, and off course, pulling down all the required images.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_reproducibility"&gt;Reproducibility&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One of the most important things when developing is that you know that at some point we can screw our environment, and will need to start over. There&amp;#8217;s times where we know the action we&amp;#8217;re going to do can be problematic, and we could probably make a safe point, so if we do something wrong, we can easily revert back the state. This is easy if you just save the configuration to be able to revert back.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster snapshot-save&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In the event of a problem, you&amp;#8217;ll might want to go back to a safe configuration:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster snapshot-list
oc-cluster snapshot-restore {snapshot-id}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
For simplicity, snapshots are made only on running clusters, but can be restored if there&amp;#8217;s no running cluster or the cluster running is the one for the snapshot.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This concept of making save points can be greatly extended, and also is prone to errors if when you restore an environment some images are no longer available. This problem is mostly for self built images.
One extension to this concept is having the ability to provide local snapshots, that will be removed if the cluster is removed, and global snapshots, that can be used to recreate a cluster at any moment, and could be made transportable. And this leads us to our next topic.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_packaging_transport"&gt;Packaging/Transport&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Packaging of a cluster is a concept very important for when doing workshops. I do want 40 people in a room to have the exact same thing so I can teach them a lesson and they can experiment themselves. For this, there&amp;#8217;s no easy solution, but as long as they have the tooling, a full cluster can be fully automated for a workshop. How?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Providing a download link that will do the installation/bootstrapping of all the needed things, a-la installer. So really there&amp;#8217;s no transport, but there&amp;#8217;s a way to bootstrap the same package for everyone.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This, that sounds really cool and easy, it&amp;#8217;s the most complex of all the tasks, and it is mainly because of the variety of operating systems existing out there. If I just had to focus on mac and linux, it could be very simple, but having to also support windows users it becomes an impossible. At least for me. Hence this requirement is not yet fulfilled.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster install {URL}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_using_proxies"&gt;Using proxies&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And last but not least, the support for proxies. This one, that seems easy, is also one of the most complex topics, and this is mostly because the support that OpenShift provides for proxies is not transportable. I&amp;#8217;ll explain myself better. As a developer, I might need to work some time at the office, where I have a proxy to access the internet. At home I might not need the proxy. This scenario is not easily solved in OpenShift, where you&amp;#8217;d need to play with ENV variables being set/unset for every build/deployment every time you move in or out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;My idea would be something like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc-cluster enable-proxy {proxy}
oc-cluster disable-proxy&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;But as easy as it looks, I haven&amp;#8217;t figured out yet if this is possible, and how.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_existing_tooling"&gt;Existing tooling&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As I said at the beginning, I&amp;#8217;m using a command called &lt;strong&gt;oc-cluster&lt;/strong&gt; and it&amp;#8217;s because it uses internally OpenShift&amp;#8217;s &lt;strong&gt;oc&lt;/strong&gt; client tool and the &lt;strong&gt;cluster&lt;/strong&gt; option. I found this &lt;strong&gt;oc cluster&lt;/strong&gt; a good way to bootstrap and use a cluster locally on my &lt;strong&gt;mac&lt;/strong&gt; but even on &lt;strong&gt;linux&lt;/strong&gt; as it can use Docker native. If you decide to use &lt;strong&gt;docker-machine&lt;/strong&gt; my command will not work. There&amp;#8217;s many advantages to using docker locally, but there&amp;#8217;s also some disadvantages. Hopefully the disadvantages can be easily solved but the advantages can not be easily taken with other approaches, as when using &lt;strong&gt;docker-machine&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Advantages I see:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You can use your local file system for persistent volumes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You don&amp;#8217;t have a virtualization layer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Image are directly available to all the clusters once pulled.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can share volumes between different clusters, even if they are not running.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Disadvantages I see:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Packaging and transportation with VM could be made easy, but then, there&amp;#8217;s many virtualization out there to make it work on all, or the most important.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Removal of built images is easier, as the images are built into the VM. Deleting the VM, deletes all built images. This can also be solved with the tooling, as there is a feature coming that will provide labels to the images created, so every cluster will label their images. Removing the cluster, will remove their images.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Probably there&amp;#8217;s more, but these are the ones I can think of right now.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_options"&gt;Options&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are some options out there, some of them more portable, but also, less flexible. As I&amp;#8217;m developing this tool just for me, I focus on something that will work for me, but as I think that most of what works for me could be made work for anyone, I&amp;#8217;m here sharing these thoughts with you.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Options:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CDK, ADB&lt;/strong&gt;: Using Virtualization through Vagrant and using vagrant plugins. It&amp;#8217;s portable but very heavy weight and outdated.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenShift.org All-in-one&lt;/strong&gt;: Same as before. Although it&amp;#8217;s up to date and it doesn&amp;#8217;t use plugins it&amp;#8217;s heavyweight. Even I&amp;#8217;m the author of it, I know it has many limitations, and I&amp;#8217;m just limiting the use of it to those use cases I can not still cover, like doing workshops with Windows users :-(&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Minishift&lt;/strong&gt;: It uses lightweight virtualization, but still don&amp;#8217;t provide many of the additional features I need. I would used it and extend it, but since it&amp;#8217;s written in go, I can not contribute to it. I find this a great option, probably the best. Although I don&amp;#8217;t like the name of the commands used, I think will be the way to move forward, and also it is based on &lt;strong&gt;minikube&lt;/strong&gt;, which seems to have adoption on &lt;strong&gt;Kubernetes&lt;/strong&gt; community, which is also great. The maintainer is a great guy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Plain oc cluster&lt;/strong&gt;: This provides a great foundation, but in no way is something usable per se for developers. Just having a default that makes configuration ephemeral is something that for a developer is not interesting. But as the tool is a great cluster bootstrapper, I use it, and try to ask for features that will make developer&amp;#8217;s use case through our tool more interesting and easy. Also the maintainer is a great guy.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_final_comments"&gt;Final comments&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I love OpenShift, I love Kubernetes. I think it is a great platform to run your containers at scale, but I still see that for developers there&amp;#8217;s a steep learning and usability curve. I hope that one day, Java developers (well really any developer) will deploy locally on Kubernetes/OpenShift and not plain docker. Also that they keep developing in plain Java, using their IDEs, building their artifacts or images however they want (s2i, docker build on OpenShift or maven and docker build locally), but that the proces it&amp;#8217;s easy for them to use.
I think that for them to adopt a platform like this, the development process needs to be:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Easy. Not many additional steps to use the local platform.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fast. It needs to be as fast as without using the local platform.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Integrated. They can use the same tools to work on their local platform.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is one of the required steps to have an environment (local platform) to use. Following should be to be easy to collaborate between your local and remote environments. But that, should be the topic of another post.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As always, if you want to comment, please use tweeter.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Download the &lt;strong&gt;&lt;a href="https://github.com/openshift-evangelists/oc-cluster-wrapper"&gt;oc-cluster&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">In this blog, I'm going to describe what are my requirements when looking for a way to develop locally using OpenShift</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2016-07-01:/2016/07/configuring-your-app-2/</id>
    <title type="html">Configuring your application, Part 2</title>
    <published>2016-07-01T09:00:00Z</published>
    <updated>2016-07-01T09:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2016/07/configuring-your-app-2/"/>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;In a real world, your applications will be transitioning from environment to environment, from development to testing and into production, as part of their lifecycle. In a container world, applications are assembled into one or many container images, hence what will be promoted are images.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog I will demonstrate &lt;a href="http://blog.openshift.com/configuring-your-application-part-1"&gt;the concepts we learnt about externalizing configuration&lt;/a&gt; in your image promotion scenarios.
As Veer &lt;a href="https://blog.openshift.com/promoting-applications-across-environments/"&gt;has previously showed&lt;/a&gt;, OpenShift is a platform where we can easily model the concept of stages/environments per application, and we can promote an application (image) from environment to environment just by tagging it accordingly in the project.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this example, I will be using the same application I used before, and I will create two projects simulating two different stages/environments for my application:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;node-app-dev&lt;/strong&gt; will model the development stage and will be owned by user &lt;strong&gt;dev&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;node-app-test&lt;/strong&gt; will model the testing stage and will be owned by user &lt;strong&gt;test&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This application will be deployed with the exact same BuildConfig in both projects, but for each, a different configuration will be used by means of deploying different values in the ConfigMap. dev user, will have an additional task of building the application from source before deploying it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ git clone https://github.com/jorgemoralespou/ose-app-promotion-configmap.git

$ cd ose-app-promotion-configmap/example2

$ oc login 10.2.2.2:8443 -u dev -p dev
$ oc new-project node-app-dev
$ oc create -f configmap-dev.json
$ oc create -f node-app-deployment.json
$ oc create -f node-app-build.json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;These commands will create a new project called node-app-dev, as user dev, and will deploy a ConfigMap, with a message and background color that will be used in development environment. Additionally, it will create the deployment configuration for the application and it will build our application from source code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once the process is finished, we will be able to see the result:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/configmaps/node-app-dev.png" alt="Example app in development"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now, as user &lt;strong&gt;test&lt;/strong&gt;, we will create a ConfigMap with different contents,  reflecting our test environment , but we will use exactly the same DeploymentConfig like before. The reason for that is, we are separating the application from its configuration, by leveraging the ConfigMap resource.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ git clone https://github.com/jorgemoralespou/ose-app-promotion-configmap.git

$ cd ose-app-promotion-configmap/example2

$ oc login 10.2.2.2:8443 -u test -p test
$ oc new-project node-app-test
$ oc create -f configmap-test.json
$ oc create -f node-app-build.json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this project, there will be no application deployed because no image has been tagged into the test project yet:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/configmaps/node-app-test.png" alt="Example app in test before promotion"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There is one security requirement to allow dev user to tag into the test project and for a user in test project to pull down the image from the repository.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Since we are fans of fine grained security, I will be creating a new role, image-tagger, that will be granted the rights to tag an ImageStream. That role will be assigned to the dev user in the test project. This action needs to be executed as an cluster admin user:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;$ oc login 10.2.2.2:8443 -u admin -p admin
$ oc create -f - &amp;amp;lt; &amp;amp;lt; EOF
{
      "kind": "ClusterRole",
      "apiVersion": "v1",
      "metadata": {
        "name": "image-tagger"
      },
      "rules": [
        {
          "verbs": [
            "get",
            "list",
            "create",
            "update",
            "edit"
          ],
          "attributeRestrictions": null,
          "apiGroups": null,
          "resources": [
            "imagestreamimages",
            "imagestreamimports",
            "imagestreammappings",
            "imagestreams",
            "imagestreamtags"
          ]
        }
      ]
    }
EOF

$ oc adm policy add-role-to-user image-tagger dev -n node-app-test&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Additionally, we also need the user from test project to be able to pull down the image from dev project. But since in OpenShift, by default, the deployment is done by the &lt;strong&gt;deployment&lt;/strong&gt; ServiceAccount, we need to assign the role accordingly&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc adm policy add-role-to-user system:image-puller system:serviceaccount:node-app-test:deployer -n node-app-dev&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that all the required permissions are in place, we can have &lt;strong&gt;dev&lt;/strong&gt; user to promote our application. For this he will just tag the image in the node-app-test project, and it will be automatically deployed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc login 10.2.2.2:8443 -u dev -p dev
$ oc tag node-app-dev/node-app:latest node-app-test/node-app:latest&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can now verify that the image has been promoted, and is now running in the testing environment, showing the configuration for this environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/configmaps/node-app-test-2.png" alt="Example app in test after promotion"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog we have demonstrated a way of separating configuration from application so that the process of promoting an application gets easier, requiring almost none customizations of the base resources being deployed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This blog example can be fully executed in the &lt;a href="https://www.openshift.org/vm/"&gt;Openshift Origin all-in-one Vagrant image&lt;/a&gt;, by doing:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ git clone https://github.com/jorgemoralespou/ose-app-promotion-configmap.git

$ cd ose-app-promotion-configmap/example2

$ oc login 10.2.2.2:8443 -u dev -p dev
$ oc new-project node-app-dev
$ oc create -f configmap-dev.json
$ oc create -f node-app-deployment.json
$ oc create -f node-app-build.json

$ oc login 10.2.2.2:8443 -u test -p test
$ oc new-project node-app-test
$ oc create -f configmap-test.json
$ oc create -f node-app-deployment.json


$ oc login 10.2.2.2:8443 -u admin -p admin
$ oc create -f roles.json
$ oc adm policy add-role-to-user image-tagger dev -n node-app-test
$ oc adm policy add-role-to-user system:image-puller system:serviceaccount:node-app-test:deployer -n node-app-dev

$ oc login 10.2.2.2:8443 -u dev -p dev

$ echo "If you want to promote the application, you can:"
$ echo "    oc tag node-app-dev/node-app:latest node-app-test/node-app:latest"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">In a real world, your applications will be transitioning from environment to environment, from development to testing and into production, as part of their lifecycle....</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2016-06-09:/2016/06/configuring-your-app-1/</id>
    <title type="html">Configuring your application, Part 1</title>
    <published>2016-06-09T09:00:00Z</published>
    <updated>2016-06-09T09:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2016/06/configuring-your-app-1/"/>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Kubernetes 1.2, released more than a month ago, has brought many interesting additions to the Kubernetes platform, but there’s one, that relates to configuration management, that’s especially relevant for application developers, this is &lt;a href="http://kubernetes.io/docs/user-guide/configmap/"&gt;ConfigMap&lt;/a&gt;. In this blog entry I will share some experiences and tips on using ConfigMap that goes beyond what one of our engineers and Kubernetes contributor, Paul Morie, recently &lt;a href="http://blog.kubernetes.io/2016/04/configuration-management-with-containers.html"&gt;blogged about it&lt;/a&gt;. We will take advantage of this new feature in a real application that we will be promoting through different environments, from development through testing into production.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One of the challenges that we face as developers is the need to externalize application configuration as this will probably be different per environment or per deployment. In OpenShift, Docker, and Kubernetes, developers have been externalizing this configuration into Environment variables, allowing every deployment to have different values for runtime configuration. This has been a fantastic way to adhere to the third rule of the &lt;a href="http://12factor.net/"&gt;12factor&lt;/a&gt; methodology, “&lt;a href="http://12factor.net/config"&gt;store config in the environment&lt;/a&gt;”. When you think that what we, as users of OpenShift, are deploying into the platform is not a container but rather an application, that can be composed of one or multiple containers, we understand that the configuration per deployment really spans greater context than the container itself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We need a way of having all the configuration used/needed per application centralized, so that changes in configuration will not impact the definition of the deployment. This is what ConfigMap is for.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The official &lt;a href="http://kubernetes.io/docs/user-guide/configmap/"&gt;Kubernetes documentation&lt;/a&gt; states:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="quoteblock"&gt;
&lt;blockquote&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Many applications require configuration via some combination of config files, command line arguments, and environment variables. These configuration artifacts should be decoupled from image content in order to keep containerized applications portable. The ConfigMap API resource provides mechanisms to inject containers with configuration data while keeping containers agnostic of Kubernetes. ConfigMap can be used to store fine-grained information like individual properties or coarse-grained information like entire config files or JSON blobs.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;So, what type of configuration can we provide to an application or deployment?
It will typically fall under one of these categories:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Single configuration value expressed as an environment variable for the container.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Command line arguments in a container.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple configuration values typically set in a configuration file.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let’s explore how we can use ConfigMaps:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I will demonstrate ConfigMap with a simple node.js app. This application will print a message as body content and will have background color configurable. We will externalize configuration into a ConfigMap. The code for the application is on &lt;a href="https://github.com/jorgemoralespou/ose-app-promotion-configmap/blob/master/node-app/server.js"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;First required thing is to create a ConfigMap to hold the configuration values you want to make available to the deployment. My node.js application will get it’s background color from a property named “color” in a file named “/etc/node-app/node-app.config” in the container. It will also, look for an environment property named message for a string to be show as background message.
The configuration file contents that will be used is:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;color=blue&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let’s create a ConfigMap, named &lt;strong&gt;config&lt;/strong&gt;, with both a literal text, message=&lt;strong&gt;Hello world!&lt;/strong&gt;, and the configuration file:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc create configmap config \
            --from-literal=message=’Hello world!’ \
            --from-file=ui.properties
configmap "config" created&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let’s verify the contents of our ConfigMap.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;$ oc get configmap/config -o json
{
    "kind": "ConfigMap",
    "apiVersion": "v1",
    "metadata": {
        "name": "config",
    },
    "data": {
        "message": "Hello world!",
        "ui.properties": "color=blue\n"
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
Some internal metadata has been removed from output for brevity.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that I have a ConfigMap with the configuration my application requires, I’m going to deploy an application that will make use of it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In my &lt;a href="https://github.com/jorgemoralespou/ose-app-promotion-configmap/blob/master/node-app/server.js"&gt;sample app&lt;/a&gt;, I will consume the configuration provided by the ConfigMap, mapping the ConfigMap property &lt;strong&gt;message&lt;/strong&gt; to the environment variable &lt;strong&gt;BACKGROUND_MSG&lt;/strong&gt; the application expects, and also mapping the &lt;strong&gt;ui.properties&lt;/strong&gt; into a file located in &lt;strong&gt;/etc/node-app/node-app.config&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt; "template": {
   "metadata": {
      "labels": {
         "app": "node-app",
         "deploymentconfig": "node-app"
      }
   },
   "spec": {
      "containers": [
         {
            "name": "node-app",
            "image": "node-app",
            "ports": [
               {
                  "containerPort": 8080,
                  "protocol": "TCP"
               }
            ],
            "env": [
               {
                  "name": "OPENSHIFT_NODEJS_PORT",
                   "value": "8080"
               },
               {
                  "name": "BACKGROUND_MESSAGE",
                  "valueFrom": {
                     "configMapKeyRef": {
                        "name": "config",
                        "key": "message"
                      }
                   }
                }
             ],
             "volumeMounts":[
                {
                   "name": "app-config",
                   "mountPath": "/etc/node-app/"
                }
             ],
             "resources": {},
             "terminationMessagePath": "/dev/termination-log",
             "imagePullPolicy": "Always"
           }
        ],
        "volumes": [
           {
              "name": "app-config",
              "configMap": {
                 "name": "config",
                 "items": [
                    {
                       "key": "ui.properties",
                       "path": "node-app.config"
                    }
                 ]
              }
           }
        ],
        "restartPolicy": "Always",
        "terminationGracePeriodSeconds": 30,
        "dnsPolicy": "ClusterFirst",
        "securityContext": {}
     }
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Configuration is assembled at deployment time, so when the application is deployed and there is no ConfigMap that satisfies the DeploymentConfig, we will have a warning event in our Event log that will help us diagnose the misconfiguration that prevented the deployment to start:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/configmaps/configmap-example-error.png" alt="Misconfiguration"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/configmaps/configmap-example.png" alt="ConfigMap example"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One important thing to know is, when a ConfigMap is mounted as a volume, we can change the contents of the ConfigMap, and the mounted file in the container will be eventually updated, when the kubelet on the node re-synchs the pod, providing for changes in configuration in running containers. The running application needs to provide a mechanism to reload configuration changes when they happen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog we have demonstrated a way of externalizing configuration of an application. Remember, ConfigMaps are GA in Kubernetes 1.2 and OpenShift 3.2 and some improvements are still to come. Just take these simple &lt;strong&gt;restrictions&lt;/strong&gt; into account:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ConfigMaps must be created before they are consumed in pods.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ConfigMaps reside in a namespace. They can only be referenced by pods in the same namespace.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The example shown in this blog can be fully executed in the Openshift Origin all-in-one Vagrant image, by doing:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ git clone https://github.com/jorgemoralespou/ose-app-promotion-configmap.git
$ cd ose-app-promotion-configmap/example1
$ oc new-project configmap-example
$ oc create -f configmap-example.json
$ oc create -f node-app-deployment.json
$ oc create -f node-app-build.json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="videoblock"&gt;
&lt;div class="content"&gt;
&lt;iframe src="https://www.youtube.com/embed/vKDLz2OXu7k?rel=0" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=vKDLz2OXu7k"&gt;See a video in action&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</content>
    <summary type="html">Kubernetes 1.2, released more than a month ago, has brought many interesting additions to the Kubernetes platform, but there’s one, that relates to configuration management, that’s especially relevant for application developers...</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2016-04-15:/2016/04/understanding-SAs_and-SCCs/</id>
    <title type="html">Understanding Service Accounts and SCCs</title>
    <published>2016-04-15T09:00:00Z</published>
    <updated>2016-04-15T09:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2016/04/understanding-SAs_and-SCCs/"/>
    <content type="html">&lt;div id="preamble"&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We launched OpenShift 3.0 back in June 2015 and I have had the pleasure of speaking with users all over Europe and the EMEA region to help them get up and running with deploying applications on the platform. One of the features that developers and administrator often ask questions about are Service Accounts and Security Context Constraints. In this blog post, I will provide a simple introduction into both concepts, how they work and their usage.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_security_context_constraints_scc"&gt;Security Context Constraints (SCC)&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;a href="https://docs.openshift.org/latest/architecture/additional_concepts/authorization.html#security-context-constraints"&gt;official documentation states&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="quoteblock"&gt;
&lt;blockquote&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift provides security context constraints (SCC) that control the actions that a pod can perform and what it has the ability to access.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In short, when we execute a container, we want to guarantee that the capabilities required by that container to run are satisfied, while at the same time we also want OpenShift to be a secure Container Application platform. For this reason we can not allow any container to get access to unnecessary capabilities or to run in an insecure way (e.g. privileged or as root).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift guarantees that the capabilities required by a container are granted to the user that executes the container at &lt;a href="https://docs.openshift.org/latest/architecture/additional_concepts/authorization.html#admission"&gt;admission time&lt;/a&gt;. Admission is done based on the identity of the user executing the pod and the pod’s service account (introduced later in this blog).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The OpenShift Container Application Platform provides a set of predefined Security Context Constraints that can be used, modified or extended by any administrator. The SCCs that can be used are as follows:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc get scc
NAME              PRIV   CAPS  HOSTDIR  SELINUX    RUNASUSER         FSGROUP   SUPGROUP  PRIORITY
anyuid            false  []    false    MustRunAs  RunAsAny          RunAsAny  RunAsAny  10
hostaccess        false  []    true     MustRunAs  MustRunAsRange    RunAsAny  RunAsAny  &amp;lt;none&amp;gt;
hostmount-anyuid  false  []    true     MustRunAs  RunAsAny          RunAsAny  RunAsAny  &amp;lt;none&amp;gt;
nonroot           false  []    false    MustRunAs  MustRunAsNonRoot  RunAsAny  RunAsAny  &amp;lt;none&amp;gt;
privileged        true   []    true     RunAsAny   RunAsAny          RunAsAny  RunAsAny  &amp;lt;none&amp;gt;
restricted        false  []    false    MustRunAs  MustRunAsRange    RunAsAny  RunAsAny  &amp;lt;none&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;By default, the execution of any container will be granted the &lt;strong&gt;restricted&lt;/strong&gt; SCC and only the capabilities defined by that SCC.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc describe scc restricted
Name:                restricted
Priority:               &amp;lt;none&amp;gt;
Access:
  Users:             &amp;lt;none&amp;gt;
  Groups:               system:authenticated
Settings:
  Allow Privileged:        false
  Default Add Capabilities:      &amp;lt;none&amp;gt;
  Required Drop Capabilities:    KILL,MKNOD,SYS_CHROOT,SETUID,SETGID
  Allowed Capabilities:       &amp;lt;none&amp;gt;
  Allowed Volume Types:       configMap,downwardAPI,emptyDir,persistentVolumeClaim,secret
  Allow Host Network:         false
  Allow Host Ports:        false
  Allow Host PID:          false
  Allow Host IPC:          false
  Read Only Root Filesystem:     false
  Run As User Strategy:             MustRunAsRange
    UID:             &amp;lt;none&amp;gt;
    UID Range Min:            &amp;lt;none&amp;gt;
    UID Range Max:            &amp;lt;none&amp;gt;
  SELinux Context Strategy:         MustRunAs
    User:               &amp;lt;none&amp;gt;
    Role:               &amp;lt;none&amp;gt;
    Type:               &amp;lt;none&amp;gt;
    Level:              &amp;lt;none&amp;gt;
  FSGroup Strategy:                 MustRunAs
    Ranges:             &amp;lt;none&amp;gt;
  Supplemental Groups Strategy:     RunAsAny
    Ranges:             &amp;lt;none&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As can be seen in the previous description of the &lt;strong&gt;restricted&lt;/strong&gt; SCC, a list of users and groups can be specified. In order to grant a user or group a specific SCC, a cluster administrator can execute the following command:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oadm policy add-user-to-scc &amp;lt;scc_name&amp;gt; &amp;lt;user_name&amp;gt;
$ oadm policy add-group-to-scc &amp;lt;scc_name&amp;gt; &amp;lt;group_name&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_service_accounts"&gt;Service Accounts&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The &lt;a href="https://docs.openshift.org/latest/dev_guide/service_accounts.html"&gt;official documentation states&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="quoteblock"&gt;
&lt;blockquote&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When a person uses the command line or web console, their API token authenticates them to the OpenShift API. However, when a regular user’s credentials are not available, it is common for components to make API calls independently. For example:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Replication controllers make API calls to create or delete pods&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Applications inside containers could make API calls for discovery purposes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;External applications could make API calls for monitoring or integration purposes&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Service accounts provide a flexible way to control API access without sharing a regular user’s credentials&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As you can see, there are many use cases for Service Accounts, and if we dive into the first use case aforementioned, we need to understand that OpenShift (and Kubernetes) are not synchronous in the execution of their commands.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/sa_scc/Eventual_consistency.png" alt="Asynch state consolidation"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When a user wants to deploy an application, he creates a DeploymentConfig resource, which describes a desired state (as can be seen in the picture above - step 1). From this point, a set of controllers (admission, replication controller, scheduler,&amp;#8230;&amp;#8203;), running on the master server, will be monitoring those definitions and will execute necessary actions on the OpenShift platform in order to provide consistency between the desired and actual state (as can be seen in the picture above - step 2). This will happen as soon as the controllers try to consolidate the cluster state.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;What this really means is, the actions are executed by the OpenShift controllers and not by the actual user, that expressed the desired state. This leads to the situation where we need to identify who&amp;#8217;s executing the actions the controllers are invoking.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;By default, OpenShift creates three service accounts per project for building, deploying and running an application (see &lt;a href="https://docs.openshift.org/latest/dev_guide/service_accounts.html#default-service-accounts-and-roles"&gt;the official documentation&lt;/a&gt; for more details).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When a user creates anyobject in OpenShift it will use these default Service Accounts, but a different one can be specified within the object configuration.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;{
   "kind": "DeploymentConfig",
   "apiVersion": "v1",
   "metadata": {...},
   "spec": {
      ...
      "template": {
         ...
         "spec":{
            "containers": [
            ],
            ...
            "serviceAccountName": "myserviceaccount"
         }
      }
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One reason to use a dedicated service account in a deployment configuration is to allow an application running within a pod to use a set of privileges or capabilities other than those granted by the &lt;strong&gt;default&lt;/strong&gt; service account. This default service account will only have access to all the capabilities defined by the &lt;strong&gt;restricted&lt;/strong&gt; SCC, as out of the box OpenShift will add every authenticated user to the restricted SCC (as can bee seen in the output of the execution of “oc describe scc restricted” shown above). This includes the default service account which is not explicitly included in any other SCC.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Since every service account has an associated username, it can be added to any specific SCC in a similar way as we have done previously with users and groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As an example, we might want to run an application that needs access to mount hostPath volumes, or we might want to run an application with a specified user and not a random user OpenShift will use as default (as detailed in &lt;a href="https://blog.openshift.com/getting-any-docker-image-running-in-your-own-openshift-cluster/"&gt;this blog&lt;/a&gt;), or we might want to restrict the container&amp;#8217;s filesystem to be readonly, and forcing every write to be on external storage. There are many other situations that might require us to change the capabilities provided by default.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This leads to the conclusion of this blog with my advice:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;“Every time you have an application/process that requires a capability not granted by the restricted SCC, create a new, specific service account and add it to the appropriate SCC. But, if there is no SCC that perfectly suits your needs, instead of using the best fit one, &lt;a href="https://docs.openshift.org/latest/admin_guide/manage_scc.html#creating-new-security-context-constraints"&gt;create a new SCC&lt;/a&gt; tailored for your requirements, and finally set it for the deployment configuration (as described above).”&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc create serviceaccount useroot

$ oc patch dc/myAppNeedsRoot --patch '{"spec":{"template":{"spec":{"serviceAccountName": "useroot"}}}}'

$ oc adm policy add-scc-to-user anyuid -z useroot&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Above you can see my advice in action, creating a new service account named &lt;em&gt;useroot&lt;/em&gt;, modifying the deployment configuration for &lt;em&gt;myAppNeedsRoot&lt;/em&gt; and then adding the serviceaccount to the &lt;em&gt;anyuid&lt;/em&gt; SCC as the application defined needs to run as user root in the container. Note that I haven&amp;#8217;t created a specific SCC since anyuid meets my needs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
The previous example is using notation available in OpenShift Origin 1.1.4+ and OpenShift Enterprise 3.2+.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I’ve seen many users granting access to a user/serviceaccount to the privileged SCC to avoid going through this exercise, and this is can be a big security problem, so take my word of caution.
&amp;lt;/group_name&amp;gt;&amp;lt;/scc_name&amp;gt;&amp;lt;/user_name&amp;gt;&amp;lt;/scc_name&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">We launched OpenShift 3.0 back in June 2015 and I have had the pleasure of speaking with users all over Europe and the EMEA region to help them</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2016-01-18:/2016/01/speed-java-builds/</id>
    <title type="html">Improving Build Time of Java Builds on OpenShift</title>
    <published>2016-01-18T09:00:00Z</published>
    <updated>2016-01-18T09:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2016/01/speed-java-builds/"/>
    <content type="html">&lt;div id="preamble"&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As you might know, OpenShift 3 Enterprise provides Middleware Services (xPaas), which is a set of Java based images for JBoss EAP, JBoss EWS (Tomcat), JBoss Fuse Integration Services, JBoss A-MQ, JBoss Decision Server and JBoss Data Grid. Also, OpenShift Origin provides an additional JBoss based images for Wildfly, our application server community project. All these images are &lt;a href="https://github.com/openshift/source-to-image/"&gt;source-to-image (S2I)&lt;/a&gt; enable, that means that will get your application source code built (using Maven) and layered into the application container.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When working with Maven, it is very common to use a Central Artifact Repository Manager in your organization for centralizing and managing all the required and generated dependencies, as well as providing you with isolation from the real location of the artifacts in the Internet and some security mechanisms, amongst other features. During my life as a developer and consultant I&amp;#8217;ve been working with Nexus Artifact Manager for this purpose. I will not say that it&amp;#8217;s the best or worst, but only that it is the one most familiar to me, and because of that, I will be using it in my OpenShift install.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;It is important to note that everything I will describe can be executed in OpenShift Enterprise or Origin, the only requirement is, that if you&amp;#8217;re using the Middleware Services images you should have the corresponding subscriptions for running them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The first thing we need to do is to lay out our OpenShift architecture. I&amp;#8217;ve decided to deploy Nexus as a service in OpenShift, for that purpose I have created a &lt;a href="https://github.com/jorgemoralespou/nexus-ose/tree/master/nexus/nexus-container"&gt;Nexus image&lt;/a&gt; (not supported) that I will be building and deploying internally in my OpenShift instance, in a project that I&amp;#8217;ve called &lt;strong&gt;ci&lt;/strong&gt;. This project name is important as it will be used to reference the nexus instance. It is part of the service DNS name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc new-project ci --display-name="Continuous Integration for OpenShift" --description="This project holds all continuous integration required infrastructure, like Nexus, Jenkins,..."

$ oc create -f https://raw.githubusercontent.com/jorgemoralespou/nexus-ose/master/nexus/ose3/nexus-resources.json -n ci&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="dlist"&gt;
&lt;dl&gt;
&lt;dt class="hdlist1"&gt;The steps above will create a project called &lt;strong&gt;ci&lt;/strong&gt;, and it will add some OpenShift resources to the project, namely&lt;/dt&gt;
&lt;dd&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A nexus &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/nexus/ose3/nexus-resources.json#L8-L15"&gt;&lt;strong&gt;ServiceAccount&lt;/strong&gt;&lt;/a&gt; for using in build&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/nexus/ose3/nexus-resources.json#L16-L69"&gt;&lt;strong&gt;BuildConfig&lt;/strong&gt;&lt;/a&gt; for building the Nexus image, based on Centos7, that will be published into a &lt;strong&gt;nexus&lt;/strong&gt; ImageStream. When the BuildConfig gets deployed, a nexus build will be triggered.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
I&amp;#8217;ve used the &lt;a href="https://github.com/sonatype/docker-nexus/blob/master/oss/Dockerfile"&gt;official sonatype nexus image&amp;#8217;s Dockerfile&lt;/a&gt; as base and extended with my own requirements for the purpose of this blog, like making sure any user will be able to deploy the image with an OpenShift restricted policy, or adding configuration to use Red Hat&amp;#8217;s JBoss mave repositories.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The build will take some time, so &lt;strong&gt;be patient!&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/nexus_build.png" alt="Nexus build"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Both &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/nexus/ose3/nexus-resources.json#L70-L80"&gt;centos7&lt;/a&gt; and &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/nexus/ose3/nexus-resources.json#L81-L96"&gt;nexus&lt;/a&gt; &lt;strong&gt;ImageStream&lt;/strong&gt; definitions&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/nexus_imagestreams.png" alt="ImagesStreams"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Two &lt;strong&gt;Template&lt;/strong&gt;`s called &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/nexus/ose3/nexus-resources.json#L97-L291"&gt;nexus-ephemeral&lt;/a&gt; and &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/nexus/ose3/nexus-resources.json#L292-L511"&gt;nexus-persistent&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/template.png" alt="Templates"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The templates that are provided as part of the loaded resources will allow you to deploy an instance of the Nexus image built, using the nexus ServiceAccount, and configured to have a service on port 8081 and a route on whatever hostname you decide, for external access. Also, these templates will allow you to have a persistent instance of Nexus, using a &lt;a href="https://docs.openshift.org/latest/dev_guide/volumes.html"&gt;PersistentVolume&lt;/a&gt; or working in an ephemeral mode, where if the nexus replica dies, you&amp;#8217;ll lose all of your cached dependencies. For testing purposes, it&amp;#8217;s much easier to setup the ephemeral instance, but for a more real usage, you should consider only the persistent image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There is full instruction on how to set the persistent volume and all the requirements in the &lt;a href="https://github.com/jorgemoralespou/nexus-ose"&gt;README file in the Github repository&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this example, I will deploy the ephemeral version, with the following command:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;oc new-app --template=nexus-ephemeral --param=APPLICATION_HOSTNAME=nexus.apps.10.2.2.2.xip.io&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can also deploy your nexus instance using the OpenShift console:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/nexus_template_instance.png" alt="Create a nexus instance"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;It is very important to understand that the nexus instance will not be deployed until the build process has finished, and this can take quite some time, so &lt;strong&gt;be patient!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/nexus_pod.png" alt="Nexus deployed"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
The value provided to APPLICATION_HOSTNAME is dependant on your installation. My OpenShift environment default application domain is apps.10.2.2.2.xip.io
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We can access our nexus instance through the &lt;strong&gt;APPLICATION_HOSTNAME&lt;/strong&gt; value we have provided, and check what repositories are in there. Default credentials for this nexus instance are (&lt;strong&gt;admin/admin123&lt;/strong&gt;). It is important to note, that this Nexus server comes already configured with some Red Hat JBoss repositories, to allow our S2I images to fetch the appropriate dependencies.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/nexus_console.png" alt="Repository view"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;What we need now is a way of instructing our JBoss S2I builder images to use this nexus instance as artifact repository manager. There is some alternatives to this, of which I will show two of them.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_using_the_provided_s2i_builder"&gt;Using the provided S2I builder&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;JBoss EAP S2I Builder Image version 1.2, which is the latest version of the builder image, that comes with OpenShift Enterprise 3.1, it provides an environment variable that can be set to point to a maven mirror url, unsurprisingly it is called &lt;strong&gt;MAVEN_MIRROR_URL&lt;/strong&gt;. I will use that variable to get the maven artifacts through our Nexus instance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To check that our builds will use our internal nexus instance, we can browse to the public group page and verify that there is no dependency currently stored.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/repo_empty.png" alt="Empty group"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let&amp;#8217;s create a new project and create a sample application using nexus.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc new-project eap-nexus-builds --display-name="EAP builds with Nexus" --description="Building Applications in EAP using Nexus for dependency management"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For the application, we will be using the EAP S2I Builder image, and we will use the default sample project, and we will set a build MAVEN_MIRROR_URL.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/eap_app.png" alt="Creating an EAP app using Nexus"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You should notice that I&amp;#8217;ve used internal DNS name of our nexus instance, which is &lt;strong&gt;nexus.ci.svc.cluster.local&lt;/strong&gt;, which follows the pattern &amp;lt;service-name&amp;gt;.&amp;lt;project&amp;gt;.svc.cluster.local for services. This is a very powerful feature of OpenShift that provides DNS names for every service, &lt;a href="https://docs.openshift.org/latest/architecture/additional_concepts/networking.html#openshift-dns"&gt;and much more&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When building the application, we will notice that maven dependencies are being pulled from our nexus instance, instead of the default public Red Hat JBoss' repositories.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/eap_app_build.png" alt="EAP Builds"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once our build is finished, we will also see how our nexus repository artifact group is filled with all the dependencies that have been pulled down.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/repo_full.png" alt="Dependencies in repo"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And we will have our application running.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/eap_builds.png" alt="Builds"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here, we can a historical view of the builds before and after setting MAVEN_MIRROR_URL. The first build in OpenShift always takes longer than any other build as it has to push all the base layers to the registry after the build. Successive builds will just push the application layer. From build #2 to #5 we can see the time it takes a normal build, without using Nexus, averaging &lt;strong&gt;1 minute and 13 seconds&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Build #7 introduces the change with MAVEN_MIRROR_URL set, but as this is the first build after the environment variable has been set, it still took &lt;strong&gt;1 minute and 8 seconds&lt;/strong&gt; to complete. This build was populating Nexus with all the pulled down dependencies.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In builds #8 to #10 we can see that the average time it takes now to build is &lt;strong&gt;42 seconds&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As can be seen, we get an average benefit of &lt;strong&gt;31 seconds&lt;/strong&gt; in building time after introducing our integration with an artifact repository manager, like Nexus.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_modifying_the_s2i_builder"&gt;Modifying the S2I builder&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Not always one can have the comfort of working with S2i builder images that expose the ability to set a Maven mirror like the Middleware Services images provided by Red Hat does, in that cases you need to think of other mechanisms to integrate these images with an artifact repository manager.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The options can vary, ranging from  the most obvious, modify or extend the builder image, using incremental builds, up to creating builder image from scratch. Since I do not like modifying existing images, especially those created by others, I will show how to extend existing Wildfly S2I Builder images to make use of a Nexus artifact repository manager. The same approach can be used with any other builder image, and some other technologies that use or can benefit from the use of an artifact repository manager, especially that Nexus or Artifactory support storing dependencies for other languages than just java.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I have created a file that will install all the required resources needed to work with the Nexus instance provided in the OpenShift install. These resources are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;3 &lt;strong&gt;BuildConfigs&lt;/strong&gt;, for &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L8-L58"&gt;Wildfly 8&lt;/a&gt;,  &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L59-L109"&gt;Wildfly 9&lt;/a&gt; and  &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L110-L160"&gt;Wildfly 10&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;6 &lt;strong&gt;ImageStreams&lt;/strong&gt;, one for each of the original ImageStreams for every Wildfly version (&lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L110-L160"&gt;8&lt;/a&gt;, &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L110-L160"&gt;9&lt;/a&gt; and &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L228-L260"&gt;10&lt;/a&gt;) and another one for each of the modified S2I builder images for Wildfly integrated with nexus (&lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L261-L283"&gt;8&lt;/a&gt;, &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L284-L305"&gt;9&lt;/a&gt; and &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/wildfly-nexus-resources.json#L306-L327"&gt;10&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The change that I’ve done to the default Wildfly S2I builder image is as simple as &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/8.1/Dockerfile#L1-L3"&gt;providing an overloaded settings.xml file in my custom S2I builder&lt;/a&gt; images that points to the &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/builders/wildfly-nexus/8.1/settings.xml#L17"&gt;nexus artifact repository manager&lt;/a&gt;. This change is the easiest to prove this functionality, although probably a better option would be to provide environment variable to customize the assembly process.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To install the Wildfly version:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc new-project wildfly-nexus-builds --display-name="Wildfly builds with Nexus" --description="Building Applications in Wildfly using Nexus for dependency management"

$ oc create -f https://raw.githubusercontent.com/jorgemoralespou/nexus-ose/master/builders/wildfly-nexus/wildfly-nexus-resources.json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once we have our custom Wildfly S2I images built,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/wildfly-nexus-builds.png" alt="Builds"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;we can just create a sample application with them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc new-app --docker-image=wildfly-nexus-9 --strategy=source --code=https://github.com/bparees/openshift-jee-sample.git --name='wildfly-nexus-sample'&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here, we see as well that our build process is fetching the required maven dependencies from the provided Nexus artifact repository manager.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/wildfly_builds.png" alt="Builds"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This first build took &lt;strong&gt;3 minutes and 11 seconds&lt;/strong&gt;, it includes building with the plain wildfly-9 image available on Github, and the time needed to pull down the image. This image was not doing any dependency management.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In the second build, I updated the BuildConfig to use wildfly-nexus-9 builder image and this build took &lt;strong&gt;1 minutes and 24 seconds&lt;/strong&gt;. The reason for that is that Nexus was caching all the dependencies, since I used a clean nexus instance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;On the third and fourth build, all the dependencies were already cached in Nexus and build time dropped to &lt;strong&gt;37 and 35 seconds&lt;/strong&gt;, respectively.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As in the previous example, with EAP, we get a benefit of more than 40 seconds in our build time by using an artifact repository manager, like Nexus.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_using_incremental_build"&gt;Using incremental build&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Another option, I’ve mentioned before, we can use to improve Maven based Java builds in OpenShift is to enable the &lt;a href="https://docs.openshift.com/enterprise/3.1/dev_guide/builds.html#incremental-builds"&gt;incremental builds&lt;/a&gt;. Unfortunately not all images support this feature, since it requires the existence of &lt;a href="https://docs.openshift.com/enterprise/3.1/creating_images/s2i.html#s2i-scripts"&gt;save-artifacts&lt;/a&gt; script, responsible for saving artifacts used during builds. In our cases these will be maven dependencies. This will have the same behavior as having a local maven repository into the build image itself, with the drawback of reaching out for the previously built image and getting the dependencies out of it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To test this mode, I have created a &lt;a href="https://raw.githubusercontent.com/jorgemoralespou/nexus-ose/master/other/eap-incremental/eap-incremental-resources.json"&gt;sample resources file&lt;/a&gt; that can be easily tested.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc new-project eap-incremental-builds --display-name="EAP incremental builds" --description="Building Applications in EAP using incremental build mode"

$ oc create -f https://raw.githubusercontent.com/jorgemoralespou/nexus-ose/master/other/eap-incremental/eap-incremental-resources.json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;After we&amp;#8217;ve created the resources, let&amp;#8217;s do some builds and look at the times.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/eap_incremental_build.png" alt="EAP incremental build"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As can be seen in the image above, the times for the second and third build, which are the builds benefiting from the stored artifacts takes much less time, &lt;strong&gt;48 and 47 seconds&lt;/strong&gt;, but it&amp;#8217;s the same time it takes when using the artifact repository manager, so there is no additional benefit in time, although it is much simpler for those images that support incremental mode, as the developer will only need to specify &lt;a href="https://github.com/jorgemoralespou/nexus-ose/blob/master/other/eap-incremental/eap-incremental-resources.json#L57"&gt;a flag in the BuildConfig&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/eap_incremental_build_log.png" alt="EAP incremental buildlog"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this example, the application and pulled down dependencies are not adding a big overhead in size to the initial eap64-openshift S2I image, only 7 MB.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/eap_image_sizes.png" alt="EAP incremental build"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;But we need to be careful with this approach as there are other images or applications that will have much more dependencies, and the size of the generated image can grow enormously. 130 MB in the following example using Fuse Integration Services.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/speed_java_builds/fis_image_sizes.png" alt="FIS incremental build"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_summary"&gt;Summary&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For every application that we build we will be getting a performance benefit by caching into an artifact repository manager it&amp;#8217;s dependencies. Initially we will be perceiving a performance benefit for the second and subsequent builds of every application, but as the artifact repository manager stores more and more dependencies this benefit will be also seen in initial builds of new applications, and most of the dependencies will already be cached.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, we can use incremental builds to get better performance on Java based builds, but it is important to understand that even this approach is easier to set up there are some drawbacks for this approach, like the need for the image to support incremental mode. Also, in this scenario, as the build process saves the dependencies within the image being built it means that if successive builds are run in different nodes, every node will have to first pull down the image from the OpenShift’s Docker registry which might take longer than pulling down the dependencies again.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The most important benefit of using Nexus or any other artifact repository dependency manager is the security and the fact that dependencies downloaded by one developer/build will be reused over all the builds using the same dependencies. Whereas in the case of incremental builds only the dependencies downloaded during previous build can be reused and only by the same build. This might have huge impact for any Java-based organization.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog, I&amp;#8217;ve highlighted how we can improve the build time of Maven based Java builds in OpenShift, but also a very important topic is the use of the internal DNS service names to reference from one project to another. The only caveat to this, is that if we are using the multi-tenant OVS networking plugin, our cluster administrators will have to make visible our &lt;strong&gt;ci&lt;/strong&gt; project to all other projects:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oadm pod-network make-projects-global ci&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;/project&amp;gt;&amp;lt;/service-name&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">Since we released OpenShift 3 back in July 2015 one of the most common questions I get from developers is how to get better build time for Java based builds...</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2015-09-03:/2015/09/deploying-springboot/</id>
    <title type="html">Using OpenShift for Enterprise Grade Spring Boot Deployments</title>
    <published>2015-09-03T09:00:00Z</published>
    <updated>2015-09-03T09:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2015/09/deploying-springboot/"/>
    <content type="html">&lt;div id="preamble"&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We live in a polyglot world where developers are using a vast array of different technologies to create applications that perform well, while also having the ability to scale to meet the demands of their application users. Of course, it is very easy to show the supported languages and runtimes that OpenShift provides out of the box, but to be realistic, many developers would like to see how we can bring other leading technologies into OpenShift and use them seamlessly. We built OpenShift 3 around Docker to embrace a standard container runtime and packaging format and give OpenShift developers access to the huge ecosystem of Docker-packaged software stacks. Kubernetes then adds web scale orchestration to OpenShift, which is critical for deploying complex microservices that span multiple containers across multiples hosts. As a result, the ability to run virtually any runtime or framework on the OpenShift platform is now a reality.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Today, I’ve decided to create an application (to be more precise a set of microservices) using the popular Spring Boot technology and deploy it on OpenShift 3. In this post, I’m going to walk you through all of the steps required, as well as provide the source code so you can see it in action by yourself and customize/extend it to your needs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is a summary of what I’m going to show:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Creating a Source-to-Image (S2I) builder image for Spring Boot based applications&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploying a sample set of applications developed with Spring Boot&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let’s get our hands dirty and start playing with some of this technology.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_spring_boot_s2i_builder"&gt;Spring Boot S2I Builder&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Boot applications are really very similar in structure to any other Java application. The main difference, apart from the libraries you use, is that it will pack everything as a single fat jar that will be run directly by the JVM. All of the runtime, libraries, dependencies and code will be embedded into this single jar file.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift S2I automatically generates a new Docker image for deployment, using source code provided by the developer and a corresponding Docker builder image in OpenShift. I used what &lt;a href="https://twitter.com/soltysh"&gt;&lt;em&gt;Maciej Szulik&lt;/em&gt;&lt;/a&gt; showed in his &lt;a href="https://blog.openshift.com/create-s2i-builder-image/"&gt;How to Create an S2I Builder Image&lt;/a&gt; blog post. Also, I used the &lt;a href="https://github.com/openshift/sti-wildfly"&gt;openshift/wildfly-81-centos7&lt;/a&gt; image as a source of inspiration.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I created an S2I project, and modified the Dockerfile:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Installed all the binaries I needed. In this case I installed &lt;strong&gt;java 8&lt;/strong&gt;, &lt;strong&gt;maven 3.3.3&lt;/strong&gt; and &lt;strong&gt;gradle 2.6&lt;/strong&gt; on top of the &lt;strong&gt;openshift/base-centos7&lt;/strong&gt; base image&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Modified all the labels describing the S2I image&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You may want to take a few minutes and examine the &lt;a href="https://github.com/jorgemoralespou/osev3-examples/blob/master/spring-boot/springboot-sti/Dockerfile"&gt;Dockerfile&lt;/a&gt; in more detail.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The next step in the process of getting a Spring Boot application running on OpenShift 3 is to build/generate the artifact (fat jar file) and place it into a “known” location where the image expects to find it. In order to accomplish this, we need to modify the assemble script that we are using as a base from the wildfly image.  This scripts needs to be modified to have the following capabilities:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ability to build with maven and gradle. Maven takes precedence if there is a pom.xml against having a build.gradle file&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make configurable the options to both builders via and ENV named BUILDER_ARGS with some appropriate defaults&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Place the generated artifact in a known location (/opt/openshift/app.jar)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You may want to take a few minutes and review the modified &lt;a href="https://github.com/jorgemoralespou/osev3-examples/blob/master/spring-boot/springboot-sti/.sti/bin/assemble"&gt;assemble&lt;/a&gt; script to ensure you understand all of the changes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And finally, I modified the S2I run script to run the Spring Boot application, with the following changes:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Execution of the generated artifact in the known location&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Being able to pass application parameters via an ENV named APP_OPTIONS&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You may want to look in greater detail the S2I &lt;a href="https://github.com/jorgemoralespou/osev3-examples/blob/master/spring-boot/springboot-sti/.sti/bin/run"&gt;run&lt;/a&gt; script.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Then, following instructions on &lt;a href="https://blog.openshift.com/create-s2i-builder-image/"&gt;Maciej&amp;#8217;s blog post&lt;/a&gt;, I created a test application (really two, one for maven building and one for gradle), and tested everything via using the generated Makefile.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;Great!!! Now it is time to add this S2I Builder to OpenShift 3.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;At this step you can take two approaches (with some variations). Publish your builder on Docker Hub, or just make your builder available in OpenShift..&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now, in order to do the latter, in a new project we need to:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Create an ImageStream. An ImageStream is identified as having builder images if it has a &lt;a href="https://github.com/jorgemoralespou/osev3-examples/blob/master/spring-boot/springboot-sti/springboot-sti-all.json#L83"&gt;builder tag&lt;/a&gt; in it’s definition.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a BuildConfig using my GitHub project as source and the builder ImageStream as output.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You may want to see the &lt;a href="https://github.com/jorgemoralespou/osev3-examples/blob/master/spring-boot/springboot-sti/springboot-sti-all.json"&gt;OpenShift resources definition&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To have the Spring Boot builder working on your OpenShift 3 installation, follow these simple steps:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc new-project springboot-sti
$ oc create -f https://raw.githubusercontent.com/jorgemoralespou/osev3-examples/master/spring-boot/springboot-sti/springboot-sti-all.json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I have also provided two sample instant-app templates for demonstrating usage of the builder. This is a helloworld Spring Boot sample application available in my GitHub that will be built using maven or gradle depending on the instant-app you select.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can monitor the building process for this springboot-sti image. Once the build is done, and the image is pushed into the internal docker registry in OpenShift, it is ready for use.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/springboot/springboot-sti-builder.png" alt="Building the builder"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can use one of the quickstart templates:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/springboot/springboot-templates.png" alt="Selecting a template"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Provide it with required information (application name and hostname):&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/springboot/helloworld-gradle.png" alt="Gradle helloworld instantapp"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And create the application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/springboot/helloworld-deployed.png" alt="Helloworld in OS Console"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once your application is running, you can visit it’s URL to see it in action.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/springboot//helloworld-running.png" alt="Running helloworld app"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_a_more_interesting_spring_boot_application"&gt;A more interesting Spring Boot application&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;So far, we have a running Spring Boot application. But the question is, will I be able to build and run more complex applications? Of course you can!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I created a more complex sample Spring Boot application, consisting of a web application and a messages service that stores information in memory.To keep things simple, I used the samples provided with Spring Boot distribution as source and modified two of them to allow interaction across the two samples. So our web application will be a frontend for our messages service. The web service will interact with the messages service via a Rest API.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I will use the same approach I did before, on &lt;a href="https://blog.openshift.com/part-2-creating-a-template-a-technical-walkthrough/"&gt;Part 2&lt;/a&gt; of my templates blog to show all the OpenShift resources that I will be creating. I will package everything as an &lt;a href="https://github.com/jorgemoralespou/osev3-examples/blob/master/spring-boot/sample-microservices-springboot/ose-instantapp-template.json"&gt;instant-app template&lt;/a&gt;, so it can be seen in action in an easy way.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/springboot/Template-SpringBoot-microservices.png" alt="Sample template"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To run it you will just need to load the instant-app, and instantiate it. Of course, you will need to adjust the parameters when creating your template. The required parameters are APPLICATION_NAME for the name of the application, APPLICATION_HOSTNAME will be the external DNS name where the web will be listening and APPLICATION_HOSTNAME_DATA will be the external DNS name for the Rest Endpoint for the data service.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc create -f https://raw.githubusercontent.com/jorgemoralespou/osev3-examples/master/spring-boot/sample-microservices-springboot/ose-instantapp-template.json
$ oc new-app --template=springboot-sample-microservices -p APPLICATION_NAME=springbootms,APPLICATION_HOSTNAME=web.example.com,APPLICATION_HOSTNAME_DATA=data.example.com&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This sample application will create a web component that will look like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/springboot/web.png" alt="Web application"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And a data services, that can be queried using Rest, like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$  curl http://data.example.com/
[{"id":1,"text":"Hello","summary":"World","created":1441125685591},{"id":2,"text":"Hi","summary":"Universe","created":1441125685594},{"id":3,"text":"Hola","summary":"OpenShift","created":1441125685594}]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ curl  -H "Content-type: application/json" -X POST -d '{"id":10,"text":"aaaaa","summary":"bbbbb"}'  http://data.example.com:1080
{"id":10,"text":"aaaaa","summary":"bbbbb","created":1441126793364}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$  curl http://data.example.com/
[{"id":1,"text":"Hello","summary":"World","created":1441125685591},{"id":2,"text":"Hi","summary":"Universe","created":1441125685594},{"id":3,"text":"Hola","summary":"OpenShift","created":1441125685594},{"id":10,"text":"aaaaa","summary":"bbbbb","created":1441126793364}]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Looking at the logs of both pods, you will be able to see the output of your running Spring Boot applications.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let’s first identify our pods. These will be the pods in Running state, with names starting with springbootms-data and springbootms-web:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc get pods
NAME                        READY     STATUS       RESTARTS   AGE
springboot-sti-1-build      0/1       ExitCode:0   0          48m
springbootms-data-1-1093k   1/1       Running      0          24m
springbootms-data-1-build   0/1       ExitCode:0   0          28m
springbootms-web-1-37xi2    1/1       Running      0          24m
springbootms-web-1-build    0/1       ExitCode:0   0          28m&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is similar to what you will see if you tail the log for the data service:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc logs springbootms-data-1-1093k
2015-09-01 16:41:28.019  INFO 1 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2015-09-01 16:41:28.031  INFO 1 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2015-09-01 16:41:28.239  INFO 1 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2015-09-01 16:41:28.241  INFO 1 --- [           main] c.o.e.m.r.InMemoryRepositoryApplication  : Started InMemoryRepositoryApplication in 19.117 seconds (JVM running for 20.961)
2015-09-01 16:55:36.809  INFO 1 --- [nio-8080-exec-4] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2015-09-01 16:55:36.809  INFO 1 --- [nio-8080-exec-4] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2015-09-01 16:55:36.836  INFO 1 --- [nio-8080-exec-4] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 27 ms&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And this is the content available in the tailed log for the web service:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc logs springbootms-web-1-37xi2
2015-09-01 16:41:27.410  INFO 1 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2015-09-01 16:41:27.693  INFO 1 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2015-09-01 16:41:27.703  INFO 1 --- [           main] c.o.e.m.web.SampleWebUIApplication       : Started SampleWebUIApplication in 17.639 seconds (JVM running for 20.512)
2015-09-01 16:55:36.567  INFO 1 --- [nio-8080-exec-4] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2015-09-01 16:55:36.568  INFO 1 --- [nio-8080-exec-4] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2015-09-01 16:55:36.594  INFO 1 --- [nio-8080-exec-4] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 26 ms&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As we have seen, our sample Spring Boot services application are running fine using our Spring Boot S2I builder image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;I hope you have enjoyed!!!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">e live in a polyglot world where developers are using a vast array of different technologies to create applications that perform well, while also having the ability to scale to meet the demands of their application users</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2015-08-14:/2015/08/creating-templates-2-walkthrough/</id>
    <title type="html">Part 2 - Create a template. A technical walkthrough</title>
    <published>2015-08-14T09:00:00Z</published>
    <updated>2015-08-14T09:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2015/08/creating-templates-2-walkthrough/"/>
    <content type="html">&lt;div id="preamble"&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is Part 2 of a 2 part series of blogs that will help you bringing your applications into OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that we already know what is a template, and why we should use templates, let&amp;#8217;s walk through the process of creating a template for our application.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_our_application"&gt;Our application&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For this example, we are going to bring into OpenShift an application that will display a map and perform geospatial queries to populate the map with all Major League Baseball stadiums in the United States.
Source for this application can be found in &lt;a href="https://github.com/jorgemoralespou/openshift3mlbparks"&gt;my openshift3mlbparks GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The deployment architecture will consist of:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;JBoss Enterprise Application Server with a JavaEE application as frontend tier&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MongoDB server with data corresponding to the location of the MLB Stadiums in the US as backend/data tier&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As the frontend tier is stateless, we will be able to deploy many JBoss EAP instances.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We want to access our application in a single DNS name (e.g. mlbsparks.cloudapps.example.com).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock" style="text-align: center"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/templates/OSE_Templates_blog_1.png" alt="OSE Templates blog 1"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_design_our_template"&gt;Design our template&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The first thing we will need to do is design the contents of our template. The best approach I&amp;#8217;ve found so far is to think of a template as a set of layers of resources with the following structure (from bottom up):&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenShift Images&lt;/strong&gt;: Base images we will be using for our containers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Builds&lt;/strong&gt;: Generate an image from source code (application source or Dockerfile source).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Images&lt;/strong&gt;: Images produced by the builds.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deployments&lt;/strong&gt;: What images will be deployed and how.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Abstractions&lt;/strong&gt;: Additional resources needed for our application, like networking, storage, security,&amp;#8230;&amp;#8203;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_layer_0_openshift_images"&gt;Layer 0: OpenShift images&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this first layer, we will need to define all the "base" images we will be using for our containers. These images typically will not be part of the template, but they need to be identified. These can be S2I images or plain Docker images.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="dlist"&gt;
&lt;dl&gt;
&lt;dt class="hdlist1"&gt;ImageStream&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;An image stream presents a single virtual view of related images, as it may contain images from:&lt;/p&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Its own image repository in OpenShift’s integrated Docker Registry&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Other image streams&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker image repositories from external registries.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;OpenShift stores complete metadata about each image (e.g., command, entrypoint, environment variables, etc.). Images in OpenShift are immutable.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;ImageStreamImage&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;An ImageStreamImage is used to reference or retrieve an image for a given image stream and image name. It uses the following convention for its name: &amp;lt;image stream name&amp;gt;@&amp;lt;name&amp;gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;ImageStreamTag&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;An ImageStreamTag is used to reference or retrieve an image for a given image stream and tag. It uses the following convention for its name: &amp;lt;image stream name&amp;gt;:&amp;lt;tag&amp;gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In our sample application, we will be using 2 base images:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;for the frontend component of our application, where we will be using a S2I enabled JBoss EAP image. We will be using a specific tag, 6.4 of this image. As this image will be used for building purposes, the specific usage will be defined in the Build layer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for the backend component of our application we will be using a MongoDB database. We will be using the latest available image. As this image is a ready to use image, the specific usage of this image will be defined in the Deployment layer.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
Both ImageStreams are provided by OpenShift 3 out of the box, hence they are installed in the openshift project (namespace).
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For more information see &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/builds_and_image_streams.html#image-streams"&gt;the official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_layer_1_builds"&gt;Layer 1: Builds&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This layer defines all the builds we will require for our application. A build is the process of transforming input parameters into a resulting object. Most often, the process is used to transform source code into a runnable image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="dlist"&gt;
&lt;dl&gt;
&lt;dt class="hdlist1"&gt;BuildConfig&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A &lt;a href="https://docs.openshift.com/enterprise/3.0/dev_guide/builds.html#defining-a-buildconfig"&gt;&lt;strong&gt;BuildConfig&lt;/strong&gt;&lt;/a&gt; object is the definition of the entire build process.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A build configuration consists of the following key parts:&lt;/p&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A source description (&lt;strong&gt;Where is your source code?&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A strategy for building (&lt;strong&gt;How to build your image?&lt;/strong&gt;)&lt;/p&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Source-To-Image&lt;/em&gt;: Transform your application into a runnable docker image, using a S2I image for building and running your application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Docker&lt;/em&gt;: Your Dockerfile will be built into an image. This image will contain both, the runtime and the application already built.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Custom&lt;/em&gt;: You provide the building method in a Docker image.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An output description (&lt;strong&gt;Where to place the built image&lt;/strong&gt;?)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A list of triggers (&lt;strong&gt;When and Why will the source be built?&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In our sample application we will be building the frontend component, layering our application on top of an EAP runtime.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "BuildConfig",
   "apiVersion": "v1",
   "metadata": {
      "name": "mlbparks",             # &amp;amp;lt;1&amp;amp;gt;
      "labels": {
         "application": "mlbparks"    # &amp;amp;lt;2&amp;amp;gt;
      }
   },
   "spec": {
      "source": {                     # &amp;amp;lt;3&amp;amp;gt;
         "type": "Git",               # &amp;amp;lt;4&amp;amp;gt;
         "git": {
            "uri": "https://github.com/jorgemoralespou/openshift3mlbparks.git",  # &amp;amp;lt;5&amp;amp;gt;
            "ref": "master"           # &amp;amp;lt;6&amp;amp;gt;
         },
         "contextDir":""              # &amp;amp;lt;7&amp;amp;gt;
      },
      "strategy": {                   # &amp;amp;lt;8&amp;amp;gt;
         "type": "Source",            # &amp;amp;lt;9&amp;amp;gt;
         "sourceStrategy": {
            "from": {                 # &amp;amp;lt;10&amp;amp;gt;
               "kind": "ImageStreamTag",
               "namespace": "openshift",
               "name": "jboss-eap6-openshift:6.4"
            }
         }
      },
      "output": {                     # &amp;amp;lt;11&amp;amp;gt;
         "to": {
            "kind": "ImageStreamTag",
            "name": "mlbparks:latest"
         }
      },
      "triggers": [
         {
            "type": "GitHub",         # &amp;amp;lt;12&amp;amp;gt;
            "generic": {
               "secret": "secret"
            }
         },
         {
            "type": "Generic",        # &amp;amp;lt;13&amp;amp;gt;
            "github": {
               "secret": "secret"
            }
         },
         {
            "type": "ImageChange",    # &amp;amp;lt;14&amp;amp;gt;
            "imageChange": {}
         }
      ]
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; This is the name that will identify this BuildConfig.
&amp;lt;2&amp;gt; These are the labels that will be set for this BuildConfig.
&amp;lt;3&amp;gt; This section defines where is the source for the build.
&amp;lt;4&amp;gt; It defines it is source located in a Git repository.
&amp;lt;5&amp;gt; In this URI.
&amp;lt;6&amp;gt; And using this tag/branch. This value is optional and defaults to “master” if not provided.
&amp;lt;7&amp;gt; And this subdirectory from the repository. This value is optional and defaults to the root directory of the repository.
&amp;lt;8&amp;gt; This defines which build strategy to use.
&amp;lt;9&amp;gt; Source=S2I.
&amp;lt;10&amp;gt; And this defines which S2I builder image to use.
&amp;lt;11&amp;gt; Defines where to leave the generated image if the build succeeds. It is placing it in our current project.
&amp;lt;12&amp;gt; This define that a change generated via a GitHub webhook trigger (if the source code is changed) will trigger a build.
&amp;lt;13&amp;gt; This define that a change generated via a Generic webhook trigger will trigger a build.
&amp;lt;14&amp;gt; This define that an Image Change will trigger a build. This will trigger a build if the builder image changes or is updated.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For more information see &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/builds_and_image_streams.html#builds"&gt;the official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_layer_2_images"&gt;Layer 2: Images&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This layer defines all the images produced by the builds.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In our sample application we will be producing an image defined in a new ImageStream.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "ImageStream",
   "apiVersion": "v1",
   "metadata": {
      "name": "mlbparks",            # &amp;amp;lt;1&amp;amp;gt;
      "labels": {
         "application": "mlbparks"   # &amp;amp;lt;2&amp;amp;gt;
      }
   },
   "spec": {                         # &amp;amp;lt;3&amp;amp;gt;
      "dockerImageRepository": "",   # &amp;amp;lt;4&amp;amp;gt;
      "tags": [                      # &amp;amp;lt;5&amp;amp;gt;
         {
            "name": "latest"
         }
      ]
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; Name of the ImageStream. This ImageStream will be created in the current project.
&amp;lt;2&amp;gt; Label to describe the resource relative to the application we are creating.
&amp;lt;3&amp;gt; ImageStream Specifications
&amp;lt;4&amp;gt; Docker Repository backing this image stream.
&amp;lt;5&amp;gt; List of available tags or image stream locators for this image stream.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As a result of the build process, for every build OpenShift will create a new version of the image, that we will always be tagged as latest (as seen in the BuildConfig&amp;#8217;s output spec).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For more information see &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/builds_and_image_streams.html#image-streams"&gt;the official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_layer_3_deployments"&gt;Layer 3: Deployments&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This layer defines the core of our applications. It defines what will be running in OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="dlist"&gt;
&lt;dl&gt;
&lt;dt class="hdlist1"&gt;DeploymentConfig&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/deployments.html#deployments-and-deployment-configurations"&gt;&lt;strong&gt;DeploymentConfig&lt;/strong&gt;&lt;/a&gt; is a definition of what will be deployed and running on OpenShift 3.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A deployment configuration consists of the following key parts:&lt;/p&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A replication controller template which describes the application to be deployed. (&lt;strong&gt;What will be deployed?&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The default replica count for the deployment. (&lt;strong&gt;How many instances will be deployed and running?&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A deployment strategy which will be used to execute the deployment. (&lt;strong&gt;How it will be deployed?&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A set of triggers which cause deployments to be created automatically. (&lt;strong&gt;When and Why will it be deployed?&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In our sample application we will have 2 DeploymentConfigs, one for the frontend component (JavaEE application) and another for the backend component (MongoDB).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The DeploymentConfig for our frontend component will define that:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;will have a pod with a single container, using the previously built mlbparks image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;there will be initially 1 replica&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;there will be a new deployment every time there is a new image built or there is a change in the configuration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the redeployment strategy will be "Recreate", which means discard all running pods and create new ones.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "DeploymentConfig",
   "apiVersion": "v1",
   "metadata": {
      "name": "mlbparks",                 # &amp;amp;lt;1&amp;amp;gt;
      "labels": {                         # &amp;amp;lt;2&amp;amp;gt;
         "deploymentConfig": "mlbparks",
         "application": "mlbparks"
      }
   },
   "spec": {                              # &amp;amp;lt;3&amp;amp;gt;
      "replicas": 1,                      # &amp;amp;lt;4&amp;amp;gt;
      "selector": {
         "deploymentConfig": "mlbparks"   # &amp;amp;lt;5&amp;amp;gt;
      },
      "strategy": {
         "type": "Recreate"               # &amp;amp;lt;6&amp;amp;gt;
      },
      "template": {                       # &amp;amp;lt;7&amp;amp;gt;
         "metadata": {
            "labels": {                   # &amp;amp;lt;8&amp;amp;gt;
               "deploymentConfig": "mlbparks",
               "application": "mlbparks"
            },
            "name": "mlbparks"            # &amp;amp;lt;9&amp;amp;gt;
         },
         "spec": {                        # &amp;amp;lt;10&amp;amp;gt;
            "containers": [
               {
                  "name": "mlbparks",          # &amp;amp;lt;11&amp;amp;gt;
                  "image": "mlbparks",         # &amp;amp;lt;12&amp;amp;gt;
                  "imagePullPolicy": "Always", # &amp;amp;lt;13&amp;amp;gt;
                  "env": [                     # &amp;amp;lt;14&amp;amp;gt;
                     {
                        "name": "OPENSHIFT_DNS_PING_SERVICE_NAME",
                        "value": "mlbparks-ping"
                     },
                     {
                        "name": "OPENSHIFT_DNS_PING_SERVICE_PORT",
                        "value": "8888"
                     },
                     {
                        "name": "MONGODB_USER",
                        "value": "user"
                     },
                     {
                        "name": "MONGODB_PASSWORD",
                        "value": "password"
                     },
                     {
                        "name": "MONGODB_DATABASE",
                        "value": "database"
                     }
                  ],
                  "ports": [                   # &amp;amp;lt;15&amp;amp;gt;
                     {
                        "name": "mlbparks-http",
                        "containerPort": 8080,
                        "protocol": "TCP"
                     },
                     {
                        "name": "mlbparks-ping",
                        "containerPort": 8888,
                        "protocol": "TCP"
                     }
                  ],
                  "readinessProbe": {         # &amp;amp;lt;16&amp;amp;gt;
                     "exec": {
                        "command": [
                           "/bin/bash",
                           "-c",
                           "/opt/eap/bin/readinessProbe.sh"
                        ]
                     }
                  },
                  "resources": {},
                  "terminationMessagePath": "/dev/termination-log",
                  "securityContext": {        # &amp;amp;lt;17&amp;amp;gt;
                     "capabilities": {},
                     "privileged": false
                  }
               }
            ],
            "restartPolicy": "Always",
            "dnsPolicy": "ClusterFirst"
         }
      },
      "triggers": [                           # &amp;amp;lt;18&amp;amp;gt;
         {
            "type": "ImageChange",            # &amp;amp;lt;19&amp;amp;gt;
            "imageChangeParams": {
               "automatic": true,
               "containerNames": [
                  "mlbparks"
               ],
               "from": {
                  "kind": "ImageStreamTag",
                  "name": "mlbparks:latest"
               }
            }
         },
         {                                    # &amp;amp;lt;20&amp;amp;gt;
            "type": "ConfigChange"
         }
      ]
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; This is the name that will identify this DeploymentConfig
&amp;lt;2&amp;gt; These are the labels that will describe this DeploymentConfig.
&amp;lt;3&amp;gt; Specification for the DeploymentConfig. Everything inside this section describes the DeploymentConfig configuration.
&amp;lt;4&amp;gt; Number of instances that should be created for this component/deployment
&amp;lt;5&amp;gt; This should be the same as &lt;strong&gt;name&lt;/strong&gt; (1).
&amp;lt;6&amp;gt; Strategy to use when deploying a new version of the application in case it is triggered. As defined in &lt;strong&gt;triggers&lt;/strong&gt;
&amp;lt;7&amp;gt; The template defines what will be deployed as part of this deployment (the pod)
&amp;lt;8&amp;gt; The labels to apply for the resources contained in the template (pod)
&amp;lt;9&amp;gt; Name of the pod. Every pod instance created will have this name as prefix.
&amp;lt;10&amp;gt; Defines the configuration (contents) of the pod
&amp;lt;11&amp;gt; The name of the container.
&amp;lt;12&amp;gt; The name of the image to use. &lt;a href="#note12"&gt;See note&lt;/a&gt;.
&amp;lt;13&amp;gt; What should do when deploying. As we will be building the image, we need to always pull on new deployments. Note that if the image tag is latest, it will always pull the image by default, otherwise it will default to “IfNotPresent”.
&amp;lt;14&amp;gt; A set of environment variables to pass to this container
&amp;lt;15&amp;gt; The ports that the container exposes
&amp;lt;16&amp;gt; Probe that will determine if the runtime in the container has started successfully, and traffic can be routed to it.
&amp;lt;17&amp;gt; SecurityContextContraint to use for the container
&amp;lt;18&amp;gt; The triggers that will dictate on what conditions to create a new deployment. (Deploy a new version of the pod)
&amp;lt;19&amp;gt; Create a new deployment when the latest image tag is updated
&amp;lt;20&amp;gt; Create a new deployment when there is a configuration change for this Resource.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
It is always recommended to set in every resource defined by a template a label of type &lt;strong&gt;"application": "NAME_OF_MY_APP"&lt;/strong&gt; as then you can link resources created as part of the processing of the template. This can be done resource by resource, as described here, or at once, as described later in &lt;a href="#labels"&gt;Labeling all resources in a template&lt;/a&gt;.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id="note12" class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
If there is an ImageChangeTrigger defined for a DeploymentConfig, the image spec&amp;#8217;s value gets substituted with the appropriate value for the image triggering the change. If you don&amp;#8217;t have an ImageChangeTrigger, then this value should be a valid docker pull spec (ie "openshift/mongodb-24-centos7").
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The DeploymentConfig for our backend component will define that:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;will have a pod with a single container using the MongoDB openshift base image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;there will be initially 1 replica&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;there will be a new deployment every time there is a new image built or there is a change in the configuration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the redeployment strategy will be "Recreate", which means discard all running pods and create new ones.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;have a persistent volume on the host&amp;#8217;s filesystem (not valid for HA or host failover).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "DeploymentConfig",
   "apiVersion": "v1",
   "metadata": {
      "name": "mlbparks-MongoDB",                 # &amp;amp;lt;1&amp;amp;gt;
      "labels": {                                 # &amp;amp;lt;2&amp;amp;gt;
         "application": "mlbparks"
      }
   },
   "spec": {                                      # &amp;amp;lt;3&amp;amp;gt;
      "replicas": 1,                              # &amp;amp;lt;4&amp;amp;gt;
      "selector": {
         "deploymentConfig": "mlbparks-MongoDB"   # &amp;amp;lt;5&amp;amp;gt;
      },
      "strategy": {
         "type": "Recreate"                       # &amp;amp;lt;6&amp;amp;gt;
      },
      "template": {                               # &amp;amp;lt;7&amp;amp;gt;
         "metadata": {
            "labels": {                           # &amp;amp;lt;8&amp;amp;gt;
               "deploymentConfig": "mlbparks-MongoDB",
               "application": "mlbparks"
            },
            "name": "mlbparks-MongoDB"            # &amp;amp;lt;9&amp;amp;gt;
         },
         "spec": {                                # &amp;amp;lt;10&amp;amp;gt;
            "containers": [
               {
                  "name": "mlbparks-MongoDB",         # &amp;amp;lt;11&amp;amp;gt;
                  "image": "MongoDB",                 # &amp;amp;lt;12&amp;amp;gt;
                  "imagePullPolicy": "IfNotPresent",  # &amp;amp;lt;13&amp;amp;gt;
                  "env": [                            # &amp;amp;lt;14&amp;amp;gt;
                     {
                        "name": "MONGODB_USER",
                        "value": "user"
                     },
                     {
                        "name": "MONGODB_PASSWORD",
                        "value": "password"
                     },
                     {
                        "name": "MONGODB_DATABASE",
                        "value": "database"
                     }
                  ],
                  "ports": [                          # &amp;amp;lt;15&amp;amp;gt;
                     {
                        "containerPort": 27017,
                        "protocol": "TCP"
                     }
                  ],
                  "resources": {},
                  "volumeMounts": [                   # &amp;amp;lt;16&amp;amp;gt;
                     {
                        "name": "mlbparks-MongoDB-data",
                        "mountPath": "/var/lib/MongoDB/data"
                     }
                  ],
                  "terminationMessagePath": "/dev/termination-log",
                  "securityContext": {                # &amp;amp;lt;17&amp;amp;gt;
                     "capabilities": {},
                     "privileged": false
                  }
               }
            ],
            "volumes": [                              # &amp;amp;lt;18&amp;amp;gt;
               {
                  "name": "mlbparks-MongoDB-data",
                  "emptyDir": {}
               }
            ],
            "restartPolicy": "Always",
            "dnsPolicy": "ClusterFirst"
         }
      },
      "triggers": [                                   # &amp;amp;lt;19&amp;amp;gt;
         {
            "type": "ImageChange",                    # &amp;amp;lt;20&amp;amp;gt;
            "imageChangeParams": {
               "automatic": true,
               "containerNames": [
                  "mlbparks-MongoDB"
               ],
               "from": {
                  "kind": "ImageStreamTag",
                  "namespace": "openshift",
                  "name": "MongoDB:latest"
               }
            }
         },
         {                                             # &amp;amp;lt;21&amp;amp;gt;
            "type": "ConfigChange"
         }
      ]
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; This is the name that will identify this DeploymentConfig
&amp;lt;2&amp;gt; These are the labels that will describe this DeploymentConfig.
&amp;lt;3&amp;gt; Specification for the DeploymentConfig. Everything inside this section describes the DeploymentConfig configuration.
&amp;lt;4&amp;gt; Number of instances that should be created for this component/deployment
&amp;lt;5&amp;gt; This should be the same as &lt;strong&gt;name&lt;/strong&gt; (1).
&amp;lt;6&amp;gt; Strategy to use when deploying a new version of the application in case it is triggered. As defined in &lt;strong&gt;triggers&lt;/strong&gt;
&amp;lt;7&amp;gt; The template defines what will be deployed as part of this deployment (the pod)
&amp;lt;8&amp;gt; The labels to apply for the resources contained in the template (pod)
&amp;lt;9&amp;gt; Name of the pod. Every pod instance created will have this name as prefix.
&amp;lt;10&amp;gt; Defines the configuration (contents) of the pod
&amp;lt;11&amp;gt; The name of the container.
&amp;lt;12&amp;gt; The name of the image to use. &lt;a href="#note12"&gt;See note&lt;/a&gt;.
&amp;lt;13&amp;gt; What should do when deploying.  We will only pull the image if it is not present, unless there is an ImageChange triggered in which case it will pull down the image, as we are using the :latest tag.
&amp;lt;14&amp;gt; A set of environment variables to pass to this container
&amp;lt;15&amp;gt; The ports that the container exposes
&amp;lt;16&amp;gt; Volume mounts used in the container
&amp;lt;17&amp;gt; SecurityContextContraint to use for the container
&amp;lt;18&amp;gt; Volumes required for the pod. &lt;a href="https://docs.openshift.com/enterprise/3.0/dev_guide/volumes.html"&gt;EmptyDir&lt;/a&gt; is a temporary directory on a single machine.
&amp;lt;19&amp;gt; The triggers that will dictate on what conditions to create a new deployment. (Deploy a new version of the pod)
&amp;lt;20&amp;gt; Create a new deployment when the latest image tag is updated
&amp;lt;21&amp;gt; Create a new deployment when there is a configuration change for this Resource.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For more information see &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/"&gt;the official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_layer_4_abstractions"&gt;Layer 4: Abstractions&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This layer defines all of the additional resources needed for our application to run, like networking, storage, security,&amp;#8230;&amp;#8203;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="dlist"&gt;
&lt;dl&gt;
&lt;dt class="hdlist1"&gt;Service&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/pods_and_services.html#services"&gt;service&lt;/a&gt; serves as an internal load balancer. It identifies a set of replicated pods in order to proxy the connections it receives to them. Backing pods can be added to or removed from a service arbitrarily while the service remains consistently available, enabling anything that depends on the service to refer to it at a consistent internal address.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Services are assigned an IP address and port pair that, when accessed, proxy to an appropriate backing pod. A service uses a label selector to find all the containers running that provide a certain network service on a certain port.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;Route&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;An OpenShift &lt;a href="https://docs.openshift.com/enterprise/3.0/dev_guide/routes.html"&gt;route&lt;/a&gt; exposes a service at a host name, like www.example.com, so that external clients can reach it by name.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;PersistentVolumeClaim&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;You can make a request for storage resources using a &lt;a href="https://docs.openshift.com/enterprise/3.0/dev_guide/persistent_volumes.html"&gt;PersistentVolumeClaim&lt;/a&gt; object; the claim is paired with a volume that generally matches your request.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;ServiceAccount&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/dev_guide/service_accounts.html"&gt;Service accounts&lt;/a&gt; provide a flexible way to control API access without sharing a regular user’s credentials.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt class="hdlist1"&gt;Secret&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;A &lt;a href="https://docs.openshift.com/enterprise/3.0/dev_guide/secrets.html"&gt;secret&lt;/a&gt; provides a mechanism to hold sensitive information such as passwords, OpenShift client config files, dockercfg files, etc. Secrets decouple sensitive content from the pods that use it and can be mounted into containers using a volume plug-in or used by the system to perform actions on behalf of a pod.&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
These are not all of the possible abstractions. Read the &lt;a href="https://docs.openshift.com/enterprise/3.0/welcome/index.html"&gt;official documentation&lt;/a&gt; for more.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In our example, we will need a set of services abstracting the deployments:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A service for the backend component (MongoDB). This service will be configured to target all pods running created with a label of &lt;strong&gt;deploymentConfig=mlbparks-MongoDB&lt;/strong&gt; which happens
for every pod created by the DeploymentConfig specified (as we can see in the DeploymentConfig for the backend component).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "Service",
   "apiVersion": "v1",
   "metadata": {
      "name": "MongoDB",             # &amp;amp;lt;1&amp;amp;gt;
      "labels": {
         "application": "mlbparks"   # &amp;amp;lt;2&amp;amp;gt;
      }
   },
   "spec": {
      "ports": [
         {
            "port": 27017,           # &amp;amp;lt;3&amp;amp;gt;
            "targetPort": 27017      # &amp;amp;lt;4&amp;amp;gt;
         }
      ],
      "selector": {                  # &amp;amp;lt;5&amp;amp;gt;
         "deploymentConfig": "mlbparks-MongoDB"
      }
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; Name of the service
&amp;lt;2&amp;gt; Labels describing this service
&amp;lt;3&amp;gt; Port where the service will be listening
&amp;lt;4&amp;gt; Port in the pod to route the network traffic to
&amp;lt;5&amp;gt; Label selector for determining which pods will be target for this service&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A service for the frontend component (JBoss EAP). This service will be configured to target all pods running created with a label of &lt;strong&gt;deploymentConfig=mlbparks&lt;/strong&gt; which happens
for every pod created by the DeploymentConfig specified (as we can see in the DeploymentConfig for the frontend component).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "Service",
   "apiVersion": "v1",
   "metadata": {
      "name": "mlbparks-http",           # &amp;amp;lt;1&amp;amp;gt;
      "labels": {
         "application": "mlbparks"       # &amp;amp;lt;2&amp;amp;gt;
      },
      "annotations": {
         "description": "The web server's http port"
      }
   },
   "spec": {
      "ports": [
         {
            "port": 8080,                # &amp;amp;lt;3&amp;amp;gt;
            "targetPort": 8080           # &amp;amp;lt;4&amp;amp;gt;
         }
      ],
      "selector": {
         "deploymentConfig": "mlbparks"  # &amp;amp;lt;5&amp;amp;gt;
      }
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; Name of the service
&amp;lt;2&amp;gt; Labels describing this service
&amp;lt;3&amp;gt; Port where the service will be listening
&amp;lt;4&amp;gt; Port in the pod to route the network traffic to
&amp;lt;5&amp;gt; Label selector for determining which pods will be target for this service&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;JBoss EAP currently needs an additional service for it&amp;#8217;s internal PING service, that is used for clustering purposes. This service will be configured to target all pods running created with a label of &lt;strong&gt;deploymentConfig=mlbparks&lt;/strong&gt; which happens for every pod created by the DeploymentConfig specified (as we can see in the DeploymentConfig for the frontend component).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "Service",
   "apiVersion": "v1",
   "metadata": {
      "name": "mlbparks-ping",           # &amp;amp;lt;1&amp;amp;gt;
      "labels": {
         "application": "mlbparks"       # &amp;amp;lt;2&amp;amp;gt;
      },
      "annotations": {
         "description": "Ping service for clustered applications"
      }
   },
   "spec": {
      "ports": [
         {
            "port": 8888,                # &amp;amp;lt;3&amp;amp;gt;
            "targetPort": 8888           # &amp;amp;lt;4&amp;amp;gt;
         }
      ],
      "selector": {
         "deploymentConfig": "mlbparks"  # &amp;amp;lt;5&amp;amp;gt;
      }
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; Name of the service
&amp;lt;2&amp;gt; Labels describing this service
&amp;lt;3&amp;gt; Port where the service will be listening
&amp;lt;4&amp;gt; Port in the pod to route the network traffic to
&amp;lt;5&amp;gt; Label selector for determining which pods will be target for this service&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, we want our application to be publicly available, so we expose the service providing HTTP access to the frontend component of the application as a route:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "Route",
   "apiVersion": "v1",
   "metadata": {
      "name": "mlbparks-http-route",       # &amp;amp;lt;1&amp;amp;gt;
      "labels": {
         "application": "mlbparks"         # &amp;amp;lt;2&amp;amp;gt;
      },
      "annotations": {
         "description": "Route for application's http service"
      }
   },
   "spec": {
      "host": "mlbparks.cloudapps.example.com", # &amp;amp;lt;3&amp;amp;gt;
      "to": {                                   # &amp;amp;lt;4&amp;amp;gt;
         "kind": "Service",
         "name": "mlbparks-http"
      }
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; Name of the route
&amp;lt;2&amp;gt; Set of labels to describe the route
&amp;lt;3&amp;gt; DNS name used to access our application. This DNS name needs to resolve to the ip address of the &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/routes.html#routers"&gt;OpenShift router&lt;/a&gt;.
&amp;lt;4&amp;gt; Defines that this is a route to a service with the specified name&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_the_result"&gt;The result&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is a graphical representation of the resources we have created for our application and that will be part of the template:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="imageblock" style="text-align: center"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/templates/OSEv3-Template.png" alt="OSEv3 Template"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_labeling_the_template"&gt;Labeling the template&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now, we should have a set of resources that we want to create as part of our "application" or "deployment" (sometimes how we name it can be confusing).
As we want to identify univocally the resources we are deploying as a whole, it is important that all of them have at least one label for this purpose. In the previous code we have set in all of the resources a label of:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;"application": "mlbparks"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, we can set different labels that will help us decorate some other parts of the deployment, like:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;"deploymentConfig": "mlbparks"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;that helps us identify which DeploymentConfig we will link a Service to.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="labels"&gt;Labeling all resources in a template&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A more convenient and concise way of setting labels for the resources in a template is to set the labels to the template resource instead. These labels will be set on every resource created when processing the template.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "Template",
   "apiVersion": "v1",
   "metadata": {
      ...
   },
   "labels": {                    # &amp;amp;lt;1&amp;amp;gt;
      "application": "mlbparks",
      "createdBy": "template-mlbparks"
   },
   "parameters": [
      ...
   ],
   "objects": [
      ...
   ]
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&amp;lt;1&amp;gt; Labels to describe all resources in the template.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this example we set two labels at the template scope, one that defines that all resources with that label were created by this template, and another label to describe that all resources belongs to the “mlbparks” application. There might be more resources in the future created in the project, that were not initially created by the template, but belongs to the “mlbparks” application.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_why_labels_are_important"&gt;why labels are important&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Labels can be used for filtering resources on a query, for example:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc get buildconfig --selector="application=mlbparks"
$ oc get deploymentconfig --selector="deploymentConfig=mlbparks"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Also, they can be used to delete in one operation every resource we have created, like:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc delete all --selector="application=mlbparks"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_make_it_reusable_parameterize_the_template"&gt;Make it reusable. Parameterize the template&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;It is time to make the template reusable, as that is the main purpose of a template. For this, we will:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Identify what information will be parameterized&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change values for parameters placeholders to make the template configurable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the parameters section for the template&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;After we&amp;#8217;ve done these 3 steps, parameters will be defined and the values will replace the placeholders when creating resources from this template.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_identify_parameters"&gt;Identify parameters&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;First thing we need to identify is what will be the information in the template we want to parameterize. Here we will be looking into things like the application name, git configuration, secrets, inter component communications configuration, DNS where to expose the Route, &amp;#8230;&amp;#8203;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_set_the_parameter_placeholders"&gt;Set the parameter placeholders&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once we know the parameters that we will be setting, we will replace the values with a parameter placeholder, so when we process the template, the provided values replace the placeholders.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A property placeholder will look like:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;${MY_PARAMETER_NAME}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And we will have something like the following for one of our BuildConfig:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
   "kind": "BuildConfig",
   "apiVersion": "v1",
   "metadata": {
      "name": "${APPLICATION_NAME}",
      "labels": {
         "application": "${APPLICATION_NAME}"
      }
   },
   "spec": {
      "triggers": [
         {
            "type": "Generic",
            "generic": {
               "secret": "${GENERIC_TRIGGER_SECRET}"
            }
         },
         {
            "type": "GitHub",
            "github": {
               "secret": "${GITHUB_TRIGGER_SECRET}"
            }
         },
         {
            "type": "ImageChange",
            "imageChange": {}
         }
      ],
      "source": {
         "type": "Git",
         "git": {
            "uri": "${GIT_URI}",
            "ref": "${GIT_REF}"
         }
      },
      "strategy": {
         "type": "Source",
         "sourceStrategy": {
            "from": {
               "kind": "ImageStreamTag",
               "namespace": "openshift",
               "name": "jboss-eap6-openshift:${EAP_RELEASE}"
            }
         }
      },
      "output": {
         "to": {
            "kind": "ImageStreamTag",
            "name": "${APPLICATION_NAME}:latest"
         }
      }
   }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_create_the_parameters"&gt;Create the parameters&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once we have set all the placeholders in the resources, we will create a section in the template for the parameters. There will be &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/templates.html#parameters"&gt;2 types of parameters&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Parameters with auto generated values (using a regexp like expression)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parameters with default values (maybe empty value)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Required parameters. When a parameter is required, empty value is not valid (new in OpenShift 3.0.2).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;   "parameters": [
      {
         "description": "EAP Release version, e.g. 6.4, etc.",
         "name": "EAP_RELEASE",
         "value": "6.4"
      },
      {
         "description": "The name for the application.",
         "name": "APPLICATION_NAME",
         "value": "mlbparks"
      },
      {
         "description": "Custom hostname for service routes.",
         "name": "APPLICATION_HOSTNAME"
      },
      {
         "description": "Git source URI for application",
         "name": "GIT_URI",
         "value": "https://github.com/jorgemoralespou/openshift3mlbparks.git"
      },
      {
         "description": "Git branch/tag reference",
         "name": "GIT_REF",
         "value": "master"
      },
      {
         "description": "Database name",
         "name": "MONGODB_DATABASE",
         "value": "root"
      },
      {
         "description": "Database user name",
         "name": "MONGODB_USER",
         "from": "user[a-zA-Z0-9]{3}",
         "generate": "expression"
      },
      {
         "description": "Database user password",
         "name": "MONGODB_PASSWORD",
         "from": "[a-zA-Z0-9]{8}",
         "generate": "expression"
      },
      {
         "description": "Github trigger secret",
         "name": "GITHUB_TRIGGER_SECRET",
         "from": "[a-zA-Z0-9]{8}",
         "generate": "expression"
      },
      ....
   ]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
It is important to note that we have generated a random user name and password for the database with an expression and that the values will get injected in the ENV variables for both pods (web and database), so they will be in sync with respect to the user and password credentials to use.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now we are all set, we do have a template. You can see the &lt;a href="https://github.com/jorgemoralespou/openshift3mlbparks/blob/master/mlbparks-template.json"&gt;full source of the template&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As can be seen, this template defines 8 new resources.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_create_the_template_in_openshift"&gt;Create the template in OpenShift&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We need to create the template in OpenShift to make it ready for use. We need to do it with the CLI and we will be able to create it for:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;General use&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Only for use in a Project&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_registering_the_template_for_general_use"&gt;Registering the template for General Use&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We will execute the creation of the template as user cluster-admin and the template will be registered in the &lt;strong&gt;openshift&lt;/strong&gt; project (which is internal to OpenShift for holding shared resources)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc create -f my_template.json -n openshift&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_registering_the_template_for_use_in_a_project"&gt;Registering the template for use in a Project&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We will execute the creation of the template as a user in the current project. (The user will need to have the appropriate roles to create "Template" resources in the current project)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc create -f my_template.json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If the user belongs to multiple projects, and wants to create the template in a different project from the one he&amp;#8217;s currently working on, he can do it with &lt;strong&gt;-n &amp;lt;project&amp;gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc create -f my_template.json -n &amp;lt;project&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_inspecting_a_template"&gt;Inspecting a template&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Before using a template, we need to know:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the template name&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the description of the template&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the expected parameters&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_list_all_the_available_templates"&gt;List all the available templates&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For viewing all the available templates for use (using the CLI) we will have to list the templates in the "openshift" project and in the user&amp;#8217;s current project.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc get templates -n openshift
$ oc get templates&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;From this list, we will get the name of the template we want to use.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_inspect_a_template"&gt;Inspect a template&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We need more information about the template, so we are going to describe the template:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ oc describe template mlbparks
Name:    mlbparks
Created: 7 days ago
Labels:     &amp;lt;none&amp;gt;
Description:   Application template for MLB Parks application on EAP 6 &amp;amp;amp; MongoDB built using STI
Annotations:   iconClass=icon-jboss

Parameters:
    Name:      EAP_RELEASE
    Description:  EAP Release version, e.g. 6.4, etc.
    Value:     6.4
    Name:      APPLICATION_NAME
    Description:  The name for the application.
    Value:     mlbparks
    Name:      APPLICATION_HOSTNAME
    Description:  Custom hostname for service routes.
    Value:     &amp;lt;none&amp;gt;
    Name:      GIT_URI
    Description:  Git source URI for application
    Value:     https://github.com/jorgemoralespou/openshift3mlbparks.git
    Name:      GIT_REF
    Description:  Git branch/tag reference
    Value:     master
    Name:      MONGODB_DATABASE
    Description:  Database name
    Value:     root
    Name:      MONGODB_NOPREALLOC
    Description:  Disable data file preallocation.
    Value:     &amp;lt;none&amp;gt;
    Name:      MONGODB_SMALLFILES
    Description:  Set MongoDB to use a smaller default data file size.
    Value:     &amp;lt;none&amp;gt;
    Name:      MONGODB_QUIET
    Description:  Runs MongoDB in a quiet mode that attempts to limit the amount of output.
    Value:     &amp;lt;none&amp;gt;
    Name:      MONGODB_USER
    Description:  Database user name
    Generated:    expression
    From:      user[a-zA-Z0-9]{3}

    Name:      MONGODB_PASSWORD
    Description:  Database user password
    Generated:    expression
    From:      [a-zA-Z0-9]{8}

    Name:      MONGODB_ADMIN_PASSWORD
    Description:  Database admin password
    Generated:    expression
    From:      [a-zA-Z0-9]{8}

    Name:      GITHUB_TRIGGER_SECRET
    Description:  Github trigger secret
    Generated:    expression
    From:      [a-zA-Z0-9]{8}

    Name:      GENERIC_TRIGGER_SECRET
    Description:  Generic build trigger secret
    Generated:    expression
    From:      [a-zA-Z0-9]{8}


Object Labels: template=mlbparks

Objects:
    BuildConfig      ${APPLICATION_NAME}
    ImageStream      ${APPLICATION_NAME}
    DeploymentConfig ${APPLICATION_NAME}-MongoDB
    DeploymentConfig ${APPLICATION_NAME}
    Route      ${APPLICATION_NAME}-http-route
    Service    MongoDB
    Service    ${APPLICATION_NAME}-http
    Service    ${APPLICATION_NAME}-ping&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_creating_resources_from_a_template"&gt;Creating resources from a template&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now we are ready to instantiate our template. We will provide our own values for the parameters defined in the template.
The processing of the template will create all the resources defined by the template in the current project.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_from_the_web_ui"&gt;From the Web UI&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To create the resources from an uploaded template using the web console:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic" start="1"&gt;
&lt;li&gt;
&lt;p&gt;While in the desired project, click on the "Create&amp;#8230;&amp;#8203;" button:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="imageblock" style="text-align: center"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/templates/create.png" alt="Create"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic" start="2"&gt;
&lt;li&gt;
&lt;p&gt;Select a template from the list of templates in your project, or provided by the global template library:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="imageblock" style="text-align: center"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/templates/template_selection.png" alt="Select"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic" start="3"&gt;
&lt;li&gt;
&lt;p&gt;View template parameters in the template creation screen:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="imageblock" style="text-align: center"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/templates/create_1.png" alt="View"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic" start="4"&gt;
&lt;li&gt;
&lt;p&gt;Modify template parameters in the template creation screen by clicking ‘edit parameters’:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="imageblock" style="text-align: center"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/templates/create_2.png" alt="Modify"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic" start="5"&gt;
&lt;li&gt;
&lt;p&gt;Click create. This will create all the processed resources defined in the template in the current project. Sequentially, builds and deploys will happen and finally you will have all components ready to accept connections.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="imageblock" style="text-align: center"&gt;
&lt;div class="content"&gt;
&lt;img src="/posts/images/templates/app.png" alt="Application"&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_from_the_cli"&gt;From the CLI&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;From command line, we can use new-app command to process the template (substitute the parameter placeholders with the values provided) and create the resources in OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We can create the resources using a template that is loaded in OpenShift:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;$ oc new-app mlbparks -p APPLICATION_NAME=mlbparks&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
We can also specify &lt;strong&gt;--template=mlbparks&lt;/strong&gt; instead of just the template name to be more precise.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Or we can create the resources using the template JSON file:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;$ oc new-app my_template.json -p APPLICATION_NAME=mlbparks&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
We can also specify &lt;strong&gt;--file=my_template.json&lt;/strong&gt; instead of the template file to be more precise.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_creating_a_template_from_existing_resources"&gt;Creating a template from existing resources&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Sometimes it happens that you already have some resources deployed into your project and you want to create a template out of them. OpenShift helps you on this task, and the steps you&amp;#8217;ll need will involve many of the concepts we&amp;#8217;ve already described.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Create the template from resources in your project&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parameterize the template&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploy the template into OpenShift&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instantiate the template (create resources defined in the template with the parameter values supplied by the user)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;From all these steps, only the first one is new.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_create_a_template_from_a_project"&gt;Create a template from a project&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We can use the existing command &lt;strong&gt;oc export&lt;/strong&gt; to define all the resources in the current project we want to export, and while doing it, we will instruct the command to create a template file, with &lt;strong&gt;--as-template=&amp;lt;template_name&amp;gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;$ oc export --as-template=my_template&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This will export all the resources in the current project. If we want to limit the resources that should be defined in the template, we can do so:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;// export all services to a template
$ oc export service --all --as-template=my_template

// export the services and deployment configurations labeled name=test
oc export svc,dc -l name=test --as-template=my_template&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Remember this will print the template in stdout, so if we want to have the template in a file, we can redirect the output into a file. We can also specify the format for the template as JSON or YAML.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;$ oc export -o json --as-template=my_template &amp;amp;gt; my_template.json
$ oc export -o yaml --as-template=my_template &amp;amp;gt; my_template.json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Note: Remember that this export step is really just the beginning of creating a template from existing resources. Once you have the template file, you&amp;#8217;ll have to modify it and adapt it as well as parameterize it to make it configurable.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_things_you_should_remember"&gt;Things you should remember&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Finally, some important things you should remember when creating templates.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Design your template visually, as it helps understand the required components.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provide meaningful names to resources and use labels to describe your resources (labels are used as selectors for some resources).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Templates can be shared or per-project, and common templates are in the &lt;strong&gt;openshift&lt;/strong&gt; namespace/project.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Currently there is no ability to set a Readme on templates, so be as verbose and complete in the template&amp;#8217;s description.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the resources in a template are processed and deployed, they can be modified with the CLI.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You should constrain the CPU and memory a container in a pod can use.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When the resources in a template are created, if there is a BuildConfiguration defined, it will only start an automated build if there is an ImageChange trigger defined. This will change in the next release and we will be able to launch a build on resource creation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parameterize everything a user of your template might want to customize so they can control the behavior of the template when they instantiate it.
&amp;lt;/template_name&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/none&amp;gt;&amp;lt;/project&amp;gt;&amp;lt;/project&amp;gt;&amp;lt;/note12&amp;gt;&amp;lt;/labels&amp;gt;&amp;lt;/note12&amp;gt;&amp;lt;/tag&amp;gt;&amp;lt;/image&amp;gt;&amp;lt;/name&amp;gt;&amp;lt;/image&amp;gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">This is Part 2 of a 2 part series of blogs that will help you bringing your applications into OpenShift. Now that we already know what is a template...</summary>
  </entry>
  <entry>
    <id>tag:jorgemoral.es,2015-08-13:/2015/08/creating-templates-1/</id>
    <title type="html">Part 1 - From app to OpenShift</title>
    <published>2015-08-13T09:00:00Z</published>
    <updated>2015-08-13T09:00:00Z</updated>
    <author>
      <name>Jorge Morales</name>
      <uri>http://jorgemoral.es/about/</uri>
    </author>
    <link rel="alternate" href="http://jorgemoral.es/2015/08/creating-templates-1/"/>
    <content type="html">&lt;div id="preamble"&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is Part 1 of a 2 part series of blogs that will help you bringing your applications into OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift 3 allows you to deploy your application to the cloud and the great thing is it doesn’t matter if your cloud is public, private, or even hybrid. Typically, the PaaS platform (OpenShift in this case) will provide a set of predefined runtimes that a developer can use to deploy an application on top of. This developer does not need to worry about the infrastructure, the runtime setup, or the configuration, he/she would just need to focus on their application, and what runtime to use. The PaaS platform will take care of sewing it all together and running it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;However, sometimes not all the runtimes are provided by the PaaS platform, or that the usages of these runtimes are not suitable for every application type, and there is a need for the PaaS provider to facilitate these to their users.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As a PaaS provider you’ll need to provide users with:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;runtimes (a.k.a platforms)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;configured usages of the runtimes for applications&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_runtimes"&gt;Runtimes&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As OpenShift 3 relies on containers, the runtimes will be base images that provide the underlying foundation to deploy an application (provided by the user) on top of. The containers also need to be highly configurable so there is no need to provide a single image for every use case. Instead, a different configuration provided to the image will make the runtime work as desired.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift 3 provides some base images certified and ready to use out of the box:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/s2i_images/nodejs.html"&gt;Node.js&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/s2i_images/ruby.html"&gt;Ruby&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/s2i_images/perl.html"&gt;Perl&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/s2i_images/php.html"&gt;PHP&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/s2i_images/python.html"&gt;Python&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/xpaas_images/eap.html"&gt;JBoss Enterprise Application Platform&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/xpaas_images/a_mq.html"&gt;JBoss A-MQ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/xpaas_images/jws.html"&gt;JBoss Web Server&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift provides users with the ability to inject/layer/build source code into these images, as they are created for &lt;a href="https://docs.openshift.com/enterprise/3.0/creating_images/s2i.html#overview"&gt;S2I (Source-To-Image)&lt;/a&gt; purposes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift 3 also provides some base images with database runtimes that can be used or extended:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/db_images/mysql.html"&gt;MySQL&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/db_images/postgresql.html"&gt;PostgreSQL&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.openshift.com/enterprise/3.0/using_images/db_images/mongodb.html"&gt;MongoDB&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_configured_usages_of_the_runtimes"&gt;Configured usages of the runtimes&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift 3 provides a set of predefined runtime use cases, that are user configurable, and allow for the deployment of applications. These predefined runtimes are modeled as &lt;strong&gt;OpenShift templates&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;OpenShift 3 provides the following templates that a Developer can use to simplify the build and deployment process for an application with an existing Git source repository:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;JavaEE application running on an EAP server&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;JavaEE application running on an EAP server and using an ephemeral database (PostgreSQL, MySQL, MongoDB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;JavaEE application running on an EAP server and using a persistent database (PostgreSQL, MySQL, MongoDB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Web application running on a Tomcat Container&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Web application running on a Tomcat Container and using an ephemeral database (PostgreSQL, MySQL, MongoDB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Web application running on a Tomcat Container and using a persistent database (PostgreSQL, MySQL, MongoDB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ActiveMQ brokers with ephemeral storage&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ActiveMQ brokers with persistent storage&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ephemeral database (PostgreSQL, MySQL, MongoDB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Persistent database (PostgreSQL, MySQL, MongoDB)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instant apps for Perl, Python, Ruby, PHP, Node.js&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
Instant apps are preconfigured example applications including source code that can be forked and altered, providing a quick experience deploying an app in a popular platform.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As you can probably guess, not all possible combinations and capabilities for a runtime or set of runtimes can be provided out of the box, and in many cases, the PaaS provider will have to create more of these for the end user.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_what_is_a_template"&gt;What is a template&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The official OpenShift 3 &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/templates.html"&gt;documentation&lt;/a&gt; states:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="quoteblock"&gt;
&lt;blockquote&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A template describes a set of objects that can be parameterized and processed to produce a list of objects for creation by OpenShift. The objects to create can include anything that users have permission to create within a project, for example services, build configurations, and deployment configurations. A template may also define a set of labels to apply to every object defined in the template.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This means that typically in a template we will have:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A set of resources that will be created as part of "creating/deploying" the template&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A set of values for the parameters defined in the template&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A set of labels to describe the generated resources&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A template will be defined in JSON or YAML format, and will be loaded into OpenShift for user instantiation, also known as application creation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The templates can have global visibility scope (visible for every OpenShift project) or project visibility scope (visible only for a specific project).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_benefits_of_using_templates"&gt;Benefits of using templates&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A template provides developers with an easy way to create all the necessary OpenShift resources for their application to work. This allows a developer to quickly deploy an application without having to understand all of the internals of the OpenShift 3 platform.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;As a PaaS provider you have better control on what is being created and can make better usage of your resources.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As a PaaS provider you can define different Service Level Agreements in templates, defining the amount of host resources (cpu, memory) each and every container can consume.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_predefined_templates_or_deploy_your_application_on_openshift"&gt;Predefined templates, or deploy your application on OpenShift&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Typically, the PaaS provider will provide users with a set of predefined templates that will cover all of the usages or typologies/topologies of applications that can be deployed on OpenShift.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The set of predefined templates will be accessible through the CLI or through the Web console.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When creating your application using one of these templates, the user will typically provide the template with the source for the code of the application and some other configuration items such as the application name, database credentials, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_custom_templates_or_openshiftify_your_application"&gt;Custom templates, or OpenShiftify your application&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Another use case is when you have a typology/topology of an application that does not fit into the provided templates and you want to create a template to model it. This will be the topic for the next article, a walkthrough on how to create a template for your application.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content>
    <summary type="html">This is Part 1 of a 2 part series of blogs that will help you bringing your applications into OpenShift....</summary>
  </entry>
</feed>

